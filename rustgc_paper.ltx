%&rustgc_paper_preamble
\endofdump

\begin{document}

\begin{abstract}
\noindent Rust is a non-Garbage Collected (GCed) language, but the lack of GC
makes expressing data-structures whose values have multiple owners awkward, inefficient, or both.
In this paper we explore a new design for, and implementation of GC in Rust, called
\ourgc, identifying the key challenge as finalisation. Unlike previous
approaches to GC in Rust, \ourgc maps existing Rust destructors to
finalisers: this makes GC in Rust natural to use but introduces surprising
soundness, performance, and ergonomic problems. \ourgc provides solutions for
  each of these problems.
\end{abstract}

\maketitle


\section{Introduction}

\begin{figure}[t]
\lstinputlisting[language=Rust, firstline=6, basicstyle=\footnotesize\ttfamily]{listings/first_example.rs}
\captionof{lstlisting}{An \ourgc example, showing use of the \lstinline{Gc<T>}
  type and destructors as finalisers. We create a type \lstinline{GcNode} which
  models a graph: it stores an 8 bit integer value and a reference (possibly
  \lstinline{None} (i.e.~`null'), via Rust's standard \lstinline{Option} type) to a neighbouring node
  (line 1). We add a normal Rust destructor which \ourgc is able to use as a
  finaliser when \lstinline{GcNode} is used inside \lstinline{Gc<T>} (line 2).
  Inside \lstinline{main} we create the first GCed node in the graph (line 5).
  We use Rust's normal \lstinline{RefCell} type to allow the node to be mutated
  (using the \lstinline{RefCell::borrow\_mut} method to dynamically detect mutation that
  would undermine Rust's static borrow checker rules)
  and pointed to itself (line 6): i.e.~we create a cycle using
  \lstinline{Gc<T>}. We then create a second cyclic graph (lines 7
  and 8), immediately assigning it to the \lstinline{gc1} variable (line 9):
  note this copies, rather than moves, the \lstinline{Gc<T>}.
  Doing so means that the first cyclic graph \lstinline{GcNode\{value: 1, ..\}}
  is no longer reachable, so when we force a collection (line 10) that node
  can be recognised as collectable; its finaliser is scheduled to be run (causing
  \lstinline{drop 1} to be printed out at a later point), and when done so the backing
  memory can be reclaimed. The print statement outputs \lstinline{2 2} (line 11).}
\label{fig:first_example}
\end{figure}

Amongst the ways one can classify programming languages are whether they
are Garbage Collected (GCed) or not: GCed languages enable implicit memory management;
non-GCed languages require explicit memory management (e.g~\lstinline{C}'s \lstinline{malloc} /
\lstinline{free} functions). Rust's use of affine types and ownership does not
fit within this classification: it is not GCed but it has implicit memory management.
Most portions of most Rust programs are as
succinct as a GCed equivalent, but ownership is too inflexible to express
data-structures that require multiple owners (e.g.~doubly linked lists).
Workarounds (e.g.~reference counting) impose an extra burden on the programmer,
make mistakes more likely, and often come with a performance penalty.

In an attempt to avoid such problems, there are now a number of GCs for Rust
(e.g.~\cite{manish15rustgc, coblenz21bronze, gcarena, boa, shifgrethor}). Most
introduce a user-visible type \lstinline{Gc<T>} which takes a value
of type \lstinline{T}, moves that value to the GC heap, and returns a wrapper around
a pointer to the moved value. \lstinline{Gc<T>} can be \emph{cloned} (i.e.~duplicated) and
\emph{dereferenced} to \lstinline{T} at will by the user. When no
\lstinline{Gc<T>} values can be found, indirectly or directly, from the
program's \emph{roots} (e.g.~variables on the stack, etc.),
then the underlying memory can be reclaimed.

It has proven hard to find a satisfying design and implementation for a GC for
Rust, as perhaps suggested by the number of different attempts to do so.
We identify two fundamental challenges
for GC for Rust: how to give \lstinline{Gc<T>} a familiar, idiomatic, complete
API; and how to make \emph{finalisation} (i.e.~the code that is run just before a
value is collected by the GC) safe, performant, and ergonomic. We show that
\emph{conservative} GC (i.e.~treating each reachable machine word as
a potential pointer) is necessary and sufficient to solve the API challenge,
but the finalisation challenge is more difficult.

In existing GCs for Rust, if a user needs values of type \lstinline{T} to cause a
finaliser to run, then the user must manually implement a finaliser.
Not only do most finalisers end up duplicating
existing \emph{destructors} (i.e.~code which is run just before a value is
reclaimed by Rust's implicit memory management) but this makes it impossible to
provide finalisers for types in external libraries.

The obvious solution to this problem is to allow existing Rust destructors to
be automatically used as finalisers. However, no existing GC for Rust does
this and in the nearest context to our
work, a GC proposal for C++, this ruled out as it
introduces seemingly insoluble problems~\cite[p.~32]{boehm09garbage}. We place these problems into four
categories:
(1) finalisers are prohibitively slower than destructors;
(2) finalisers can be run prematurely;
(3) running finalisers on the same thread as a paused mutator can cause race conditions and deadlocks;
(4) some safe destructors are not safe finalisers.
All are, at least to some degree, classical GC problems; all are exacerbated
in some way by Rust; and none, with the partial exception of (2), has
existing solutions.

We introduce novel solutions, relying on Rust's unusual static
guarantees, to each of these problems. We thus gain not just a better GC for
Rust, but also solutions to open GC problems. Our solutions to the problems,
in order, are:
(1) \emph{finaliser elision} statically optimises away finalisers if the
underlying destructor duplicates work the GC does anyway.
(2) \emph{premature finaliser prevention} automatically inserts barriers to prevent
optimisations or register allocation from `tricking'
the GC into collecting values before they are dead;
(3) we run finalisers on a separate thread;
(4) \emph{finaliser safety analysis}
extends Rust's type system to reject programs whose destructors are not
provably safe to be used as finalisers.

These solutions are implemented as part of \ourgc, a new GC for Rust.
Although \ourgc is not production ready, it has good enough performance
(across a number of benchmarks, its performance is \jake{geomean over whole suite}) and
other polish (e.g.~good quality error messages) that we believe it shows
a plausible path forwards for those who may wish to follow it. Furthermore,
although \ourgc is necessarily tied to Rust, we believe that most of the
techniques in this paper, particularly those related to finalisation, are
likely to generalise to other ownership-based languages.

This paper's high-level structure is: background (\cref{sec:background});
\ourgc's design (\cref{sec:alloy_design}); destructor and finaliser challenges
and solutions (\cref{sec:destructor challenges,sec:elision,sec:premature_finalise_prevention,sec:fsa}); and evaluation
(\cref{sec:evaluation}). The first three parts have the challenge that our work
straddles two areas that seem almost mutually exclusive: GC and Rust. We have
tried to provide sufficient material for readers expert in one of these
areas to gain adequate familiarity with the other, without undue prolixity, but perfection is beyond our
meagre grasp: we encourage readers to skip material they are already
comfortable with.


\section{Background}
\label{sec:background}

\subsection{Does Rust need a GC?}

\begin{figure}[t]
\lstinputlisting[language=Rust, firstline=5, basicstyle=\footnotesize\ttfamily]{listings/rc_example.rs}
\captionof{lstlisting}{
  A version of~\cref{fig:first_example} using Rust's standard reference
  counting type \lstinline{Rc<T>}. To avoid memory leaks we use \emph{weak}
  references between nodes (line 1). We again create two cyclic graphs (lines
  6--9) using \lstinline{Rc::downgrade} to create weak references (lines 7 and
  0). Since \lstinline{Rc<T>} is not copyable, we must use a manual
  \lstinline{clone} call to have both the \lstinline{rc1} and \lstinline{rc2}
  variables point to the same cyclic graph (line 10). Accessing a neighbour
  node becomes a delicate dance requiring upgrading the weak reference (line 11).
  The need to downgrade \lstinline{Rc<T>} to \lstinline{Weak<T>} and upgrade
  (which may fail, hence the \lstinline{unwrap}) back to \lstinline{Rc<T>}
  creates significant extra complexity relative to~\cref{fig:first_example}: compare
  line 11 in \cref{fig:first_example} to (the much more complex) lines 10-12
  in this \lstinline{Rc} example.
}
\label{fig:rc_example}
\end{figure}

Rust uses affine types~\citep[p.~5]{pierce04advanced} and \emph{ownership}
to statically guarantee that: a \emph{value} (i.e.~an instance of a type) has a
single owner (e.g.~a variable); an owner can \emph{move} (i.e.~permanently
transfer the ownership of) a value to another owner; and
when a value's owner goes out of scope, the value's destructor
is run and its backing memory reclaimed. An owner can pass \emph{references} to a value
to other code, subject to these static restrictions: there can be
multiple immutable references (`\lstinline{&}') to a value or a single
mutable reference (`\lstinline{&mut}'); and references cannot outlast the owner.

These basic rules mean that many Rust programs are as succinct as their equivalents
in GCed languages. This suggests that the search for a good GC for Rust may be quixotic:
intellectually stimulating, but of no practical value.

However, there are many programs which need to express data structures which
are sound but which do not fit into the restrictions of affine types and
ownerships. These are often described as `cyclic data-structures', though
the mere potential for cycles is sufficient to cause the problem
(e.g.~interpreters for dynamically typed languages are examples of programs
which must be able to create cycles, though they may not always do so).
Rust cannot directly express
such programs, forcing programmers to use various workarounds

Probably the most common -- or, at least, the most easily recognised in other's
code -- workaround is the reference counting type \lstinline{Rc<T>} in Rust's
standard library. For many data-structures, reference counting is a reasonable
solution, but using it for values which may have multiple owners requires
juggling strong and weak counts. This complicates the program (see~\cref{fig:rc_example}) and makes
it easy for values to live for shorter or longer than intended.

Another common workaround is to store values in a vector and use
integer indices into that vector. Such indices are then morally closer to
machine level pointers than normal Rust references: the indices can become
stale, dangle, or may never have been valid in the first place. The programmer
must also manually deal with issues such as detecting unused values,
compaction, and so on. In other words, such workarounds force the programmer
to write a partial GC themselves. A variant on this idea are
arenas, which gradually accumulate multiple values but free all of them in one go: values
can no longer be reclaimed too early, but, equally, individual values cannot be
reclaimed until all values are determined to be unneeded.

A type-based approach is \lstinline{GhostCell}s~\cite{yanovski21ghostcell},
which allow data-structures that have multiple owners to be built
by statically guaranteeing that
there is a single owner for the entire data-structure at any point in the
program. However, this implicitly prevents multiple owners (e.g.~in different threads)
from reading or mutating different parts of the structure.

Although it is easily overlooked, some workarounds (e.g.~\lstinline{Rc<T>})
rely on using \emph{unsafe} Rust (i.e.~parts of the language, often involving
pointers, that are not fully statically checked by the compiler). It is reasonable
to assume that widely used code, even if technically unsafe, has been pored
over sufficiently that it is mostly, perhaps even wholly, reliable in practise. It
is less reasonable to assume that `new' solutions that a programmer implements using
unsafe Rust will immediately reach the same level of reliability. Our experience
is that most Rust programmers will avoid writing new unsafe code if they can, even
if doing so might in the long-term lead to a better system.

While we do not believe that every Rust program would be improved by GC, the
variety of workarounds already present in Rust code suggests that a substantial
subset might benefit from GC.


\subsection{GC terminology}

GC is a venerable field and has accumulated terminology that can seem
unfamiliar or unintuitive. We mostly use the same terminology
as~\cite{jones16garbage}, the major parts of which we define here.

A program which uses GC is split between the \emph{mutator} (the user's program) and
the \emph{collector} (the GC itself). At any given point in time, a particular thread is either
running as a mutator or a collector. In our context, all threads
run as a collector at least sometimes, with some threads always running as a collector.
Tracing and reclamation is performed during a \emph{collection} phase. In the context of
this paper, collections are \emph{stop-the-world}, where all mutator threads
are paused while collection occurs.

A \emph{tracing} GC is one that scans memory looking
for reachable objects from a program's roots: objects that are not reachable
from the roots can then be \emph{reclaimed}. In contrast, a reference counting GC does
not scan memory, and thus cannot free objects that form a cycle. As is common
in most GC literature, henceforth we use `GC' to mean `tracing GC' unless
explicitly stated otherwise.

We refer to memory which is allocated via \lstinline{Gc<T>} as being on
the \emph{GC heap}, though in practise all heap memory in \ourgc is allocated by the
same conservative GC. We use the term `GC value' to refer both to the pointer wrapped in a
\lstinline{Gc<T>} and the underlying value on the GC heap, even though multiple
pointers / wrappers can refer to a single value on the heap, unless doing so
would lead to ambiguity.

We use ``\ourgc'' to refer to the combination of: our extension to the Rust
language; our modifications to the \lstinline{rustc} compiler; and our
integration of the Boehm-Demers-Weiser GC (\boehm) into the runtime of programs
compiled with our modified \lstinline{rustc}.


\section{\ourgc: Design and Implementation}
\label{sec:alloy_design}

In this section we outline \ourgc's basic design and implementation choices --
the rest of the paper then goes into detail on the more advanced aspects.


\subsection{Basic Design}

\ourgc provides a \lstinline{Gc<T>} type that exposes an API modelled on the
reference counting type \lstinline{Rc<T>} from Rust's standard library, because
\lstinline{Rc<T>}: is conceptually
similar to \lstinline{Gc<T>}; widely used in Rust code, and its API
familiar; and that API reflects long-term experience about what Rust programmers
need from such a type.

When a user calls \lstinline{Gc::new(v)}, the value \lstinline{v} is
moved to the GC heap: the \lstinline{Gc<T>} value returned to the user is a
simple wrapper around a pointer to \lstinline{v}'s new address. Since the
purpose of a \lstinline{Gc<T>} is to allow a value to have multiple owners,
it must not only be possible to dereference it arbitrarily many times, but
the lifetimes of those references must be allowed to overlap. To avoid undermining
Rust's ownership system, this means that dereferencing a \lstinline{Gc<T>} must
produce an immutable (i.e.~`\lstinline{&}') reference to the underlying value.
If the user wishes to mutate the underlying value, they must use other Rust
types that enable \emph{interior mutability} (e.g.~\lstinline{RefCell<T>} or
\lstinline{Mutex<T>}).

One feature that \ourgc explicitly adopts is \lstinline{Rc<T>}'s
ability to be transformed into a raw pointer (\lstinline{into_raw}) and
back (\lstinline{from_raw}). Though many programmers do not directly
encounter these functions, they are a crucial part of the link between Rust's high and
low-level features (e.g.~being used for the C Foreign Function Interface
(FFI) alongside the ability to cast Rust references to pointer types and back).
We believe that a viable GC for Rust must include this same
ability, but doing so has a profound impact: Rust allows raw pointers to be
converted to the integer type \lstinline{usize} and back\footnote{Although
it is outside the scope of this paper, it would arguably
be preferable for Rust to have different integer types for `data width' and
`address'. Modern C, for example, does this with the \lstinline{size_t} and
\lstinline{uintptr_t} types respectively. Rust now has a provenance lint to
nudge users in this general direction, but the \lstinline{as}
keyword still allows arbitrary conversions.}.

\label{conservative_gc}
Having acknowledged that pointers may end up disguised as integers, it is then
inevitable that \ourgc must be a conservative GC: if, when considered as a
pointer, a reachable word's address falls within a GCed block of memory,
then that block itself is considered reachable (and thus transitively scanned).
Since a conservative GC cannot know if a word is really a pointer, or just happens to be a sequence of
bits that also happens to make it a valid pointer, this over-approximates the
\emph{live set} (i.e.~the blocks that the GC will not reclaim). However, the
most extensive study we know of suggests the false detection rate in Java
programs is under 0.01\% of live objects~\cite{shahriyar14fast}, so it is
rarely a problem in practise.

Conservative GC occupies a grey zone in programming language semantics: in most
languages, and most compiler's internal semantics, conservative GC relies on undefined behaviour; and
some languages (including Rust) allow arbitrary `bit fiddling' on pointers that temporarily
obscures the address they are referring to. \ourgc's use of conservative GC means that it
is, formally speaking, unsound. However, conservative GC is widely used,
including in the two most widespread web browsers: Chrome uses it in its Blink
rendering engine~\citep{ager13oilpan} and Safari uses it in its JavaScript VM
JavaScriptCore~\citep{pizlo17riptide}. Even in 2024, we lack good alternatives
to conservative GC: there is no cross-platform API for precise GC; and while
some compilers such as LLVM provide some support for GC
features~\cite{llvm14statepoints}, we have found them incomplete and buggy.
Despite the potential soundness worries, conservative GC thus remains a widely
used technique.

\label{gc_is_copyable}
Conservative GC enables \ourgc to make a useful ergonomic improvement over
most other GCs for Rust whose \lstinline{Gc<T>} is only \emph{cloneable}. Such types can be duplicated, but doing
so requires executing arbitrary user code. To make the possible run-time cost of this clear, Rust has
no direct syntax for cloning: users must explicitly call \lstinline{Rc::clone(&x)}
to duplicate a value \lstinline{x}. In contrast, since \ourgc's \lstinline{Gc<T>} is just a wrapper around a pointer it
is not just cloneable but also \emph{copyable}: duplication only requires copying
bytes (i.e.~no arbitrary user code need be executed). Copying is implied by assignment,
reducing the need for a function call entirely\footnote{The lengthier
syntax \lstinline{y = Gc::clone(&x)} is available, since every copyable type is
also cloneable.}. This is not just a syntactic convenience but also reflects an underlying
semantic difference: duplicating a \lstinline{Gc<T>} in \ourgc is is a cheaper and simpler operation
than in other GCs for Rust (or, indeed, an \lstinline{Rc<T>}).


\subsection{Basic Implementation}

The most visible aspect of \ourgc is its fork, and extension of, the standard
Rust compiler \rustc. We forked \rustc~\rustcversion and have
added or changed approximately 3,150 Lines Of Code (LOC). Users must opt-in
to GC by enabling the allocator and assigning it to an arbitrarily-named variable:

\begin{lstlisting}[language=Rust, numbers=none, basicstyle=\footnotesize\ttfamily]
#![feature(gc)] use std::gc::GcAllocator;
#[global_allocator] static A: GcAllocator = GcAllocator
\end{lstlisting}

\ourgc uses the conservative Boehm-Demers-Weiser GC (\boehm)~\citep{boehm88garbage} as its collector.
Although we use some uncommon, and extend other, parts of \boehm, there is
nothing inherently unique about \boehm from \ourgc's perspective.

We made the following changes to \boehm. First, we disabled \boehm's parallel collector
because, for reasons we don't fully understand, it worsens \ourgc's
performance. Second, \boehm cannot scan pointers stored in thread locals
because these are platform dependent. Fortunately, \rustc uses LLVM's
thread local storage implementation, which stores such pointers in the
\lstinline{PT_TLS} segment of the ELF binary: we modified \boehm to scan
this ELF segment during each collection. Third,
\boehm normally dynamically intercepts thread creation calls so that it can
then can scan their stacks, but (for bootstrapping
reasons) it is unable to do so in our context: we explicitly changed \ourgc
to register new threads with \boehm.

We made one conceptually larger -- though fairly small in terms of lines of
code \laurie{how many?} -- change to \boehm, to run all finalisers on a
separate thread (see~\cref{sec:general_challenges,sec:fsa_finaliser_thread} for
motivation). We lazily create a thread dedicated to this once the collector has
first identified objects that need finalising. The finaliser thread then runs
until the end of the program waiting for further work; rather than spinning,
the collector notifies the finaliser thread of additional work via a condition
variable.


\section{Destructors and Finalisers}
\label{sec:destructor challenges}

When a value in Rust is \emph{dropped} (e.g.~the value's owner went out of lexical
scope) its destructor is automatically run. Rust destructors are formed of two
parts, run in the following order: a user-defined \emph{drop method}; and
automatically inserted \emph{drop glue}. Drop methods are optional; users
can provide one for a type by implementing the \lstinline{Drop} trait's \lstinline{drop}
method. Drop glue recursively calls destructors of contained types (e.g.~fields
in a \lstinline{struct}). Although it is common usage to conflate `destructor' in
Rust with drop methods, drop glue is an integral part of a Rust destructor:
we therefore use `destructor' as the umbrella term for both drop methods and drop glue.

Rust's destructors enable a style of programming that originated in C++ called RAII (Resource
Acquisition Is Initialization)~\cite[Section~14.4]{stroustrup97c++}: when a
value is dropped, the underlying resources it possesses (e.g.~file handles or heap memory)
are released. Whether one considers all such uses
to be RAII or not, a brief perusal of Rust code will quickly show that
types that have drop methods are used frequently and that users fairly often
implement their own drop methods.

Existing GCs for Rust have very separate notions of destructors and finalisers.
Where the former have the \lstinline{Drop} trait, the later typically have
a \lstinline{Finalise} trait. If a user type needs to be finalised, then
the user must provide an implementation of the \lstinline{Finalise} trait for that type.
However, doing so introduces a number of problems: (1) external libraries are
unlikely to provide finalisers; (2) Rust's \emph{orphan
rule}~\cite[Section~6.12]{rustlangref} prevents one implementing traits for
types defined in external libraries (i.e.~unless a library's types were
designed to support \lstinline{Gc<T>}, those types cannot be directly GCed);
(3) one cannot automatically replicate drop glue for finalisers; and (4) one
cannot replicate \rustc's refusal to allow calls to the equivalent of
\lstinline{Drop::drop}.

Programmers can workaround problems (1) and (2) in various ways. For example,
they can wrap external library types in \emph{newtypes} (zero-cost wrappers)
and implement finalisers on those instead~\cite[Section~19.3]{klabnik18rust}.
Doing so is tedious but not conceptually difficult.

Problem (3) has partial solutions: for example, ~\cite{manish15rustgc} uses the
\lstinline{Trace} macro to generate `finaliser glue' (our term) for
\lstinline{struct} fields. This runs into an unsolvable variant of problem (2):
types in external libraries will not implement this trait and cannot be
recursively scanned for finaliser glue.

Problem (4) is impossible to solve in Rust as-is. One cannot define a function
that can never be called --- what use would such a function have? It might seem
tempting to have the \lstinline{finalise} method take ownership of the value,
but \lstinline{Drop::drop} does not do so because that would not allow drop
glue to be run afterwards.

In summary: destruction is a core part of Rust; a GC for Rust ideally needs to
maintain most if not all of those properties for finalisation; but some parts
cannot be replicated in normal user code.


\subsection{General Challenges When Using Destructors as Finalisers}
\label{sec:general_challenges}

Even if there were no Rust-specific challenges to using destructors as
finalisers, we would still face the problem that finalisers and destructors
have different, and sometimes incompatible, properties. The best overall
guide to these differences, and the resulting problems, is~\cite{boehm03destructors},
supplemented by later work by some of the same authors on support
for GC in the C++ specification~\cite{boehm09garbage}\footnote{These features
were added to the C+11 specification, but do not seem to have been implemented by
compilers. C++23 removed these features.}.

An obvious difference between destructors and finalisers is when both
are run. Where C++ and Rust define
precisely when a destructor will be run\footnote{Mostly. Rust's `temporary
lifetime extension' delays destruction, but for how long is currently
unspecified.}, finalisers run at an unspecified point in time. Although
we often assume is happens after the last reference to a GCed value is lost,
finalisers can run \emph{prematurely}, that is before the equivalent
destructor~\cite[section~3.4]{boehm03destructors}.

A less obvious difference relates to where destructors and finalisers are run.
Destructors run in the same thread as the last owner of a value.
However, running finalisers in the same thread as the last owner of the value
ran in can cause race conditions and deadlocks if one or more finalisers try to access a resource that the mutator
expects to have exclusive access too~\cite[section~3.3]{boehm03destructors}.
Although such problems can
affect destructors, this is a clear case of programmer error, since they should
have taken into account the predictable execution point of destructors. Since
finalisers have no such predictable execution point, there is no way for finalisers
to safely access shared resources if they are run on the same thread. Such
problems can only be avoided by running
finalisers on a non-mutator thread: however, not all Rust destructors
are safe to run on another thread.

Finalisation and cycles are not happy bedfellows: finalisers
can reference other GCed values that are partly, or wholly, `finalised' and may
even have had their backing memory reused. A related, but
distinct, problem is the ability of finalisers to `resurrect' values by
copying the reference passed to the finaliser and storing it somewhere.


\subsection{The Challenge of Finalisers for \ourgc}

At this point we hope to have convinced the reader of two general points: a
viable GC for Rust needs to be able to use existing destructors as finalisers
whenever possible; and that finalisers, even in existing GCs, cause
various problems.

Over time, finalisers have come to be viewed with increasing suspicion. Java,
for example, has deprecated, and intends eventually removing, per-type
finalisers: instead it has introduced deliberately less flexible per-object `cleaners', whose API
prevents problems such as object resurrection~\cite{goetz21deprecated}. It
is important to differentiate such mechanisms from the \lstinline{Finalise} trait that many existing GCs for
Rust force users to manually implement: cleaners impose restrictions
to make finalisers less problematic; existing \lstinline{Finalise} traits
do not impose any such restrictions.

Our desire that \ourgc should use existing Rust destructors as finalisers whenever
possible may seem out of reach. Indeed, in the nearest
context to our work GC for C++ this solution was explicitly ruled out for GC for C++ as the
problems were thought insoluble~\cite[p.~32]{boehm09garbage}. We break these
problems down into four:
(1) finalisers are prohibitively slower than destructors;
(2) finalisers can be run prematurely;
(3) running finalisers on the same thread as a paused mutator can cause race conditions and deadlocks;
(4) some safe destructors are not safe finalisers.

Fortunately for us, Rust's unusual static guarantees, suitably expanded by
\ourgc, allow us to address each problem in novel, satisfying, ways. In the following
section, we tackle these problems in the order above, noting that we tackle problems
(1) and (2) separately, and (3) and (4) together.


\section{Finaliser Elision}
\label{sec:elision}

Finalisers are much slower to run than destructors --- running every Rust destructor
as a GC finaliser in \ourgc causes a \somrselision{felide}{all}{percent} slowdown
in our benchmark suite. In this section we show how to sidestep much of this overhead.

A variety of factors contribute to the performance overhead of finalisers, such as:
a queue of finalisers
must be maintained, whereas destructors can be run immediately; since finalisers run
some time after the last access of a value, running them is more likely to involve
cache misses; and so on. Most of these factors are inherent to any GC and
our experience of using and working on \boehm -- a mature, widely used GC -- does
not suggest that optimisations of the necessary magnitude could be made to it.

Instead, whenever possible, \ourgc \emph{elides} finalisers so that they do not need to be run at all.
We are able to do this because many Rust destructors
exclusively do work that a GC will do anyway --- when used as finalisers,
such destructors are unnecessary.

Consider the type \lstinline{Box<T>} which heap allocates space for a value;
when a \lstinline{Box<T>} value is dropped, the heap allocation will be freed
by \lstinline{Box}'s drop method. We then make two observations. First,
\lstinline{Box<T>}'s drop method solely consists of a call to \lstinline{free}\footnote{The
function in the Rust API is actually called \lstinline{deallocate}, but that
jars with the terminology we use elsewhere.}. Second, while we informally say
that \lstinline{Box<T>} allocates on the `heap' and \lstinline{Gc<T>} allocates
on the `GC heap', all allocations are made through \boehm and stored in
a single heap. Thus, when used as a finaliser,
\lstinline{Box<T>}'s drop method is unneeded\footnote{There is a subtle asymmetry here: we
cannot elide the destructors themselves, as they are still necessary to ensure
predictable destruction in non-\lstinline{Gc<T>} Rust code.}, as the underlying memory will
naturally be freed by \boehm anyway. Indeed, since the drop method only
calls \lstinline{free}, any resulting finaliser would cause the underlying
allocation to live longer than if the finaliser was not present!

This means that there is no need to run a finaliser for a type such as
\lstinline{Gc<Box<u8>>} and we can statically elide it. However, we can not
elide every \lstinline{Gc<Box<T>>} finaliser: for example, \lstinline{Gc<Box<Arc<u8>>}
(where \lstinline{Arc<T>} is the thread-safe version of \lstinline{Rc<T>})
requires a finaliser because \lstinline{Arc<T>} needs to decrement a reference
count. This may seem confusing, because in both cases \lstinline{Box<T>}'s drop
method is the same: however, the drop glue added for \lstinline{Box<Arc<u8>>}
causes \lstinline{Arc<T>}'s destructor to be run.


\subsection{Implementing finaliser elision}

\begin{algorithm}[t]
\caption{Finaliser Elision}
\label{alg:elision}
\begin{algorithmic}
\Function{RequiresFinaliser}{$T$}
    \If {\Call{Impls}{$T$, $Drop$} \AND \NOT \Call{Impls}{$T$, $DropMethodFinaliserElidable$}}
        \State \Return{true}
    \EndIf
\ForEach {$field \in type$}
    \If{\Call{RequiresFinaliser}{$field$}}
        \State \Return{true}
    \EndIf
\EndFor
\State \Return{false}
\EndFunction
\end{algorithmic}
\end{algorithm}

\label{requires_finaliser_intrinsic}
The aim of finaliser elision is to statically determine which type's destructors do
not require corresponding finalisers and elide them. Our approach is conservative,
and deals correctly with drop glue and nested data types. We implement the approach
shown in \cref{alg:elision} a \rustc compiler intrinsic \lstinline{requires_finaliser}.

In essence, \cref{alg:elision} says that any type which implements
the \lstinline{Drop} trait requires finalisation unless it also implements the
new \lstinline{DropMethodFinaliserElidable} \emph{marker trait} (i.e.~a
trait without methods). This trait and can be
used by a programmer to signify that a type's drop method need
not be called if the type is placed inside a \lstinline{Gc<T>}. However,
\lstinline{DropMethodFinaliserElidable} only refers to the `top-level' type: if
a transitively reachable field has a type which implements the \lstinline{Drop}
trait but not the \lstinline{DropMethodFinaliserElidable} trait, then the
top-level type still requires finalisation. This latter qualification is
necessary to deal with drop glue.

Even though neither normal Rust destructors or \ourgc finalisers are guaranteed
to run, a program whose destructors or finalisers never run would probably not
be usable (e.g.~leaking resources such as memory, deadlocking, etc.). We have
therefore chosen to make \lstinline{DropMethodFinaliserElidable} an unsafe
trait, because implementing it inappropriately is likely to lead undesired
(though not incorrect!) behaviour at run-time. To implement it one therefore
needs to opt in to unsafe Rust:

\begin{lstrustsmall}
unsafe impl<T> DropMethodFinaliserElidable for Box<T> {}
\end{lstrustsmall}

\ourgc modifies the standard Rust library to implement
\lstinline{DropMethodFinaliserElidable} on the following types: \lstinline{Box<T>},
\lstinline{Vec<T>}, \lstinline{RawVec<T>}, and \lstinline{HashMap<T>}. Fortunately,
not only are these types' drop methods compatible as-is with \lstinline{DropMethodFinaliserElidable},
but these types are widely used in real Rust code: as we shall see in \cref{sec:evaluation},
they are an important part of allowing us to elide significant numbers of finalisers in real code.

\begin{figure}[t]
  \begin{lstlisting}[language=Rust, numbers=none, basicstyle=\footnotesize\ttfamily,
    label={listing:elision_in_rustc}, caption={
      A simplified view of how finalisers are elided inside \ourgc. The new compiler intrinsic
      \lstinline{requires_finaliser} returns true if a finaliser is required for a
      type. The \lstinline{Gc<T>} type uses this intrinsic to ensure that the
      value is registered as requiring a finaliser. Because \lstinline{requires_finaliser}
      is a \lstinline{const} function, with optimisations turned on, it is inlined
      and the branch optimised away. In other words, the seemingly dynamic, branching code
      in \lstinline{Gc::new} turns into static, branchless code.
    }]
impl<T> Gc<T> {
  pub fn new(value: T) -> Self {
    if requires_finaliser::<T>() { Gc<T>::new_with_finaliser(value) }
    else { Gc<T>::new_without_finaliser(value) }
    ...
  }
}
\end{lstlisting}
\end{figure}

\cref{listing:elision_in_rustc} shows how we use the \lstinline{const} compiler intrinsinc
\lstinline{requires_finaliser}. \lstinline{Gc::new} uses this intrinsic to decide
whether a finaliser must be registered or not. Although this looks like
a dynamic check, in fully optimised builds it turns into a static
check: \lstinline{requires_finaliser} is
evaluated at compile-time and its result can be inlined into \lstinline{Gc::new};
this then allows the associated conditional to be removed too. In other words --
compiler optimisations allowing -- the `does this specific type require a
finaliser' checks have no run-time cost at all.


\section{Premature Finaliser Prevention}
\label{sec:premature_finalise_prevention}

\begin{figure}[tb]
\begin{lstlisting}[
  language=Rust, basicstyle=\footnotesize\ttfamily,
  caption={An example of code that, when fully optimised, can cause premature
    finalisation. We create a new struct \lstinline{S} that wraps an integer
    (line 1) with a drop method that sets the integer to zero (line 2). In the
    main method, we first move an instance of the struct into a
    \lstinline{Box<T>}, then move that into a \lstinline{Gc<T>} (line 4). We
    then obtain a Rust reference to the inner integer (line 5), which at
    run-time will be a pointer to the \lstinline{Box<T>} on the heap. At this
    point, the compiler can realise that the \lstinline{Gc<T>} is no longer
    used and overwrite \lstinline{root}'s pointer (which may be in a register). If
    a GC cycle then occurs, a finaliser might run \lstinline{S}'s drop method;
    the program will then print `0' instead of the expected `1' (line 7).},
    label={fig:premature_finalisation}]
struct S { value: u8 }
impl Drop for S { fn drop(&mut self) { self.value = 0; } }
fn main()  {
  let root = Gc::new(Box::new(S{ value: 1 }));
  let inner: &u8 = &**root.value;
  force_gc();
  println!("{}", *inner);
}
\end{lstlisting}
\end{figure}

Most of us assume that finalisers are always run after the
equivalent destructor would have run, but they can sometimes run
prematurely~\cite[section~3.4]{boehm03destructors}.
As described thus far, premature finalisation is also possible in \ourgc
(see~\cref{fig:premature_finalisation}). In this section we
show how we can turn a seemingly inefficient
approach to premature finalisation prevention into a viable solution.

There are two aspects to premature finalisation. First, language
specifications often do not define, or not precisely define, when the earliest point that a value can
be finalised is. While this means that, formally, there is no `premature' finalisation,
it seems unlikely that language designers anticipated some of the resulting
implementation surprises (see e.g.~this example in
Java~\cite{shipilev20local}). Second most compiler optimisations are
`GC unaware', so optimisations such as scalar
replacement can change the point in a program when GCed values appear to be
finalisable.

In our context, it is trivial to define premature finalisation as a (dynamic) finaliser
for a \lstinline{Gc<T>} value running before the (static) \lstinline{Gc<T>} owner
has gone out of scope. Similar to the high-level proposal mooted
in~\cite[Solution~1]{boehm07optimization}, we must therefore ensure that the dynamic
lifetime of a GC pointer matches, or exceeds, the static lifetime of the
\lstinline{Gc<T>} owner.

Our solution relies on using \lstinline{Gc<T>}'s drop method to \emph{keep
alive} GCed value for the static lifetime of the \lstinline{Gc<T>} itself. In
other words, we ensure that the conservative GC cannot observe the GCed value
being unused until all of its normal Rust owners of type \lstinline{Gc<T>} have
gone out of scope.

However, there is one major problem to overcome: copyable types such as
\lstinline{Gc<T>} are forbidden from having destructors. The fundamental
challenge we have to solve is that each copied value will have a destructor
called on it, which has the potential for an underlying value to be destructed
more than once. \ourgc explicitly allows \lstinline{Gc<T>} -- but no other
copyable type -- to have a destructor, but to ensure it doesn't cause surprises
in the face of arbitrary numbers of copies, the destructor must be idempotent.
Our task is made easier because \lstinline{Gc<T>} has no drop glue: Rust does
not add a destructor for pointer types, and from the perspective of the type
system \lstinline{Gc<T>} is simply a wrapper around a pointer type.

We therefore only need to make sure that \lstinline{Gc<T>}'s drop method
is idempotent. Fortunately, this is sufficient for our purposes: we want the drop
method to inhibit finalisation but that does not require run-time side effects.
We therefore use a memory fence in the form of a keep-alive
function. For our purposes, memory fences have both compile-time and run-time effects:
they prevent compilers from reordering computations around a given address;
and the manner in which this prevention occurs also ensure that CPUs
cannot reorder computations relevant to that address.
Keep-alive functions are highly platform (compiler, operating
system, and CPU) specific: we use \boehm's \lstinline{GC_reachable_here}
function\footnote{This is actually a macro, and our fork of \boehm provides a
function \lstinline{GC_keep_alive} to expose the macro to Rust.}
which abstracts over these details. \lstinline{Gc<T>}'s
implementation of the \lstinline{Drop} trait therefore looks as follows:

\begin{lstlisting}[language=Rust, basicstyle=\footnotesize\ttfamily]
impl<T: ?Sized> Drop for Gc<T> {
   fn drop(&mut self) { unsafe { bdwgc::GC_keep_alive(self as *mut u8) }; }
}
\end{lstlisting}


\subsection{Optimising premature finaliser prevention}

The drop method we add to \lstinline{Gc<T>} fully prevents premature
finalisation. It also naturally solves a performance problem with the suggested solution
for C++ in~\cite[Solution~1]{boehm07optimization}, which requires keeping alive
all pointers, no matter their type, for their full scope. By definition, our
solution only keeps alive \lstinline{Gc<T>} values: the compiler is free to
optimise values of other types as it so wishes. However, our approach still
imposes a performance overhead on code that uses
\lstinline{Gc<T>}: in the worst case in our benchmark suite, the overhead is
\somrsbarriers{bnaive}{fibonacci}{speedup} \laurie{this figure seems wrong}.

Fortunately, we can optimise premature finaliser prevention further by
piggy-backing on finaliser elision: if a finaliser can be
elided, there is no finaliser to be called prematurely, and no need for
resulting values to be kept alive. Intuitively, we want to avoid generating drop methods
for \lstinline{Gc<T>} types that do not require finalisation,
but this is difficult to do directly inside \rustc. Instead,
we suppress calls to the drop methods of such types: the two approaches
are functionally equivalent, though ours
does put an extra burden on dead-code elimination in the compiler tool-chain.

We add a new pass
\lstinline{remove_elidable_drops} to
\rustc's Mid-Level Intermediate Representation (MIR) processing. MIR is best
thought of as the main IR inside \rustc: it contains the complete set of
functions in the program, where each function consists of a sequence of basic
blocks. Simplifying somewhat, function and drop method calls are represented as
different kinds of \emph{terminators} on basic blocks. Terminators
reference both a callee and a successor basic block.

The \lstinline{remove_elidable_drops} pass iterates over a program's MIR,
identifies drop method terminators which reference elidable finalisers (using
the \lstinline{requires_finaliser} intrinsic from
\cref{requires_finaliser_intrinsic}), and turns them into `goto' terminators
to the successor basic basic block. \cref{alg:barrier_removal} in the appendix
gives a more formal version of this algorithm.


\section{Finaliser Safety Analysis}
\label{sec:fsa}

In this section we address two problems: running finalisers on the same thread
as a paused mutator can cause race conditions and deadlocks; and some safe destructors are not
safe finalisers. Addressing the first problem is conceptually simple --
finalisers must be run on a separate thread -- but we must ensure that doing so
is sound. We therefore consider this a specific instance of the second problem.

In this section we introduce the three main factors that constitute
Finaliser Safety Analysis (FSA).
We extend Rust's static analyses, and alter the relevant parts
of \rustc, to reject a type \lstinline{T}'s destructor if it
is not provably safe to be used as a finaliser in a \lstinline{Gc<T>}.


\subsection{Rust references}
\label{sec:fsa_rust_references}

\lstinline{Gc<T>} can store, directly or indirectly, normal Rust
references (i.e.~\lstinline{&} and \lstinline{&mut}), at which point it is
subject to Rust's normal borrow checker rules and cannot outlive the reference.
However, finalisers can dynamically extend the lifetime of a GCed value,
including any stored reference: if a finaliser accesses a reference stored in a
\lstinline{Gc<T>} it implicitly undermines Rust's borrow checking rules.
The simplest way of avoiding this problem would be to forbid \lstinline{Gc<T>}
from storing, directly or indirectly, references.

While storing references in
a \lstinline{Gc<T>} might seem pointless -- after all, doing so prevents the
\lstinline{Gc<T>} from having a dynamic lifetime, which is part of the utility
of a GC -- it is sometimes useful, including when
one is refactoring or experimenting with existing code.
FSA therefore enforces a more relaxed rule: a \lstinline{Gc<T>} can only store,
directly or indirectly, references if it has no finaliser (i.e.~\lstinline{T}
has no destructor, or finaliser elision has removed the \lstinline{Gc<T>}'s
finaliser).

To implement this aspect of FSA, \ourgc uses auto traits~\cite[Section.~11]{rustlangref},
which can be thought of as marker traits that the compiler recognises and
handles in a special way. Since we use auto traits repeatedly in FSA,
it is worth understanding how they work. In essence, an auto trait \lstinline{A}
will be automatically implemented for a type \lstinline{T} unless
one of the following is true: there is an explicit \emph{negative
implementation} of \lstinline{A} for \texttt{T}; or \texttt{T}
contains a field that is not itself \lstinline{A}. Informally, we
say that a negative implementation of an auto-trait \emph{pollutes} containing
types.

We therefore introduce a new auto trait \lstinline{ReferenceFree}, which
denotes a type which does not contain a reference. Crucially, \ourgc defines
two negative (`\lstinline{!}') implementations of \lstinline{ReferenceFree} for
reference types:

\begin{lstlisting}[language=Rust, basicstyle=\footnotesize\ttfamily]
impl<T> !ReferenceFree for &T {}
impl<T> !ReferenceFree for &mut T {}
\end{lstlisting}

Thus, thanks to auto traits, any type \lstinline{T} which implements
\lstinline{ReferenceFree} is guaranteed to be free of references. When a
program contains a \lstinline{Gc<T>} type, \ourgc checks whether it has a
finaliser: if it does,
and \lstinline{T} does not implement \lstinline{ReferenceFree}, an error is
raised.


\subsection{Destructors need to be runnable on the finaliser thread}
\label{sec:fsa_finaliser_thread}

\begin{figure}[t]
\lstinputlisting[language=Rust, basicstyle=\footnotesize\ttfamily,
 firstline=10]{listings/finaliser_deadlock.rs}
\captionof{lstlisting}{How destructors can cause deadlocks when used as
  finalisers. The mutator creates a reference-counted mutex (line 6),
  placing a copy in a \lstinline{GcNode} that immediately goes out of scope
  (line 7). The mutator then acquires the lock (line 8) but before it
  can release the lock a GC cycle occurs and the \lstinline{GcNode}'s
  finaliser run (line 9). If the finaliser is run on the same thread
  as the mutator, then it will fail to grab the lock (line 2) and cause
  a deadlock as the mutator cannot continue and release the lock.}
\label{fig:finaliser_deadlock}
\end{figure}

Virtually all destructors access state, whether that is in the GCed value (or a subpart) they are
attached to, or global state. When used as finalisers, accessing such state can
be problematic, turning `correct' destructors into `incorrect' finalisers. For
example, acquiring a lock can cause deadlocks if the mutator has already
acquired that lock and the finaliser is run on the same thread as the
mutator~\cite[Section~3.3]{boehm03destructors}. Locks are not the only problem:
data races of other kinds are also possible when destructors are run as
finalisers and can interleave with mutator code~\cite{niko13destructors}.

The solution to these problems is to ensure that finalisers are never
interleaved with mutator code on the same thread. The most general, and
practical, way to achieve this is to run finalisers on a thread(s) that never
runs mutator code. While such a thread(s) could perform other non-mutator work,
it is simplest to think of a thread dedicated solely to running finalisers and
hence we refer to it as the \emph{finaliser thread}.

We must therefore ensure that it is safe to run a type's destructor on the
finaliser thread. A conservative definition is that \lstinline{Gc<T>} is
is safe to use if \lstinline{T}'s destructor implements both of Rust's existing \lstinline{Send} (is a type safe to be
moved permanently from one thread to another?) and \lstinline{Sync} (is a type
safe to be accessed from more than one thread?) auto traits.
Note that it is not sufficient for \lstinline{T} to implement
\lstinline{Send} alone, because a finaliser may access
state (e.g.~stored in an \lstinline{Arc}) shared between a GCed value and
non-GCed value. If the finaliser runs while the non-GCed value is still in
scope, the mutator and finaliser threads may access
the underlying value simultaneously.


\subsubsection{Relaxing the \lstinline{Send + Sync} restriction}
\label{sec:relaxed}

Requiring that finalisation is only possible for types that implement both \lstinline{Send} and
\lstinline{Sync} can occasionally be frustrating, in part because more types
implement \lstinline{Send} than \lstinline{Sync}. FSA thus implements a more
relaxed check, analysing all drop methods reachable from a type's fields, to
see if those drop methods access elements that do themselves implement
\lstinline{Send} and \lstinline{Sync}.

Simplifying slightly, rather than forcing an entire type to be thread-safe, FSA
checks a weaker property: are destructor methods thread-safe? In essence, we check
all reachable code from a destructor to ensure that: any fields used implement both
\lstinline{Send} and \lstinline{Sync}: and no thread locals are used. The latter
check is necessary \laurie{i guess because \lstinline{LocalKey} is Send and Sync?}.

\jake{It's occurred to me that we have not mentioned an edge-case: thread-locals. Finalisers must not access thread-locals because we're not on the same thread anymore. We used to have such a check in Alloy, but it's no longer there (I think it got splatted in a rebase, I'm going to re-add it}

In safe Rust, the property we are checking is a non-strict subset of `does the containing
type implement both \lstinline{Send} and \lstinline{Sync}?'. However, the two
properties have subtly different natures: our original restriction checks `obviously' static properties,
but the relaxed restriction deals with `potentially' dynamic properties. The latter
is clearly harder to reason about: is it safe? We believe that
this relaxed check is compatible with Rust's semantics (at least at the time of writing),
and our examination of the compiler tool-chain
(i.e.~\rustc and LLVM) showed that it does not implement the analyses and
optimisations that could undermined our check. However, there are
other languages and implementations where our check would not be valid
(for example our assumption would be unsafe
in Java due to synchronisation removal~\cite{wang06escape}). We leave as an
open question to others as to whether Rust should deliberately permit or forbid
such checks in its semantics.

\laurie{in our benchmark suite, how often does this relaxation make a difference?}\jake{I will post a write-up here once I have the numbers from all the benchmarks}

\jake{I think we can make a more convincing argument though if we frame the
relaxation as essential for cyclic data structures which drop: without the
relaxed rule, we could not allow \lstinline{Gc<T>}s to hold references to other
Gcs if any of them had drop methods. This is because we'd have no idea whether
those Gc's value reference a \lstinline{Gc} in their drop method from within a
cycle (which is obviously unsound), and so we'd have to disallow those drops entirely.}
\laurie{i don't get it: can you give me an example?}


\subsection{Cycles and Finalisation}

\begin{figure}[tb]
\lstinputlisting[language=Rust, basicstyle=\footnotesize\ttfamily,
  firstline=5]{listings/finalisation_cycle.rs}
\captionof{lstlisting}{An example of the problems that come from mixing cycles
  and finalisation. The salient difference from~\cref{fig:first_example} is that
  the drop method sets the value of a field inside \lstinline{nbr}. Running this
  program on a strong memory model machine would non-deterministically print \lstinline{2 0} or \lstinline{1 0}
  depending on whether \lstinline{gc1} or \lstinline{gc2} is finalised first.
  The `seemingly expected' output of \lstinline{1 2} or \lstinline{2 1} would
  never be printed: whichever GCed value is finalised first changes what the
  other GCed value sees in its finaliser. As that implies, this example is
  unsound: the second finaliser to run leads to undefined behaviour.}
\label{fig:finaliser_cycle}
\end{figure}

One of the main motivations for GCs is that they solve problems with cyclic
data structures. However, finalisers can can be unsound if they access
state shared within a cycle. \cref{fig:finaliser_cycle} shows an example of undefined
behaviour when two GCed values create a cycle and both their
finalisers reference the other GCed value. Whichever order the finalisers are
run in, at least one of the finalisers will see the other GCed value as partly
or wholly `finalised'.

Most languages and systems we are aware of assume that users either don't run into
this problem (finalisation cycles are considered rare in GCed
languages~\citep[p.~229]{jones16garbage}), or know how to deal
with it when they do (e.g.~refactoring the types into parts that do and don't
require finalisation~\cite[p.~11]{boehm03destructors}). There is no fully
automatic solution to this problem, with the closest solution being those GCs
which offer weak references, allowing users to detect when finalisation cycles
have been broken, though they still have to deal with the consequences
manually.

None of the existing languages and systems we know of attempts to statically
rule out problems with finalisation and cycles. In \ourgc, in contrast, we can
make use of the explicit \lstinline{Gc<T>} type to rule out such problems. FSA
therefore forbids destructors from, directly or indirectly, dereferencing
\lstinline{Gc<T>} types. This statically guarantees that finalisers cannot have
problems in the presence of cycles.

The way this check is implemented is a variation of the `relaxed'
check of~\cref{sec:relaxed}, though here we want to check that no transitively reachable drop
methods a \lstinline{Gc<T>} field. We introduce
another auto trait \lstinline{FinalizerSafe}, whose sole negative implementation
is on \lstinline{Gc<T>} itself:

\begin{lstrustsmall}
impl<T> !FinalizerSafe for Gc<T> {}
\end{lstrustsmall}


\subsection{Bypassing FSA checks when necessary}

FSA is deliberately conservative. In particular, when checking whether drop
methods satisfy certain properties, FSA naturally checks whether all code
reachable from those drop methods satisfies those properties. If a reachable
function cannot be examined then FSA assumes it fails to meet the stated
property. This can happen because a function is externally linked (e.g.~an FFI
call to C) or due to dynamic dispatch in \emph{trait objects}, where we can't
tell which of many possible implementations of a method will actually be
called. \jake{We also do not recurse through function calls inside drop.
There's no inherent reason why we can't do this, we just didn't implement it as
just looking at drop was good enough as a prototype.(where we tested it on
existing systems at least) This is because we hook-in after inlining, which
means that we do end up with a lot of context to work with}

In some cases, users are able to prove to their satisfaction that the resulting
false positives are unnecessary (e.g.~because the C function they are calling
has no side effects). They can then can override FSA's checks by implementing
the unsafe \lstinline{FinalizerSafe} trait for a given type \jake{and Send + Sync too!}. However, because
this applies to a type, and thus all values that instantiate that type, it can
be difficult to convince oneself that doing so is correct. \jake{Also because if they have to make something Send + Sync too, this can have implications for that type when used outside of Gc -- all of a sudden, the rest of Rust thinks that your \lstinline{T} is safe to access concurrently!}

We therefore provide a second way of overriding FSA's checks with the
\lstinline{FinalizerUnchecked<T>} newtype. In essence,
\lstinline{FinalizerUnchecked} allows users to inform FSA that certain uses of
a type \lstinline{T} satisfy its properties. We still want to require the user
to explicitly opt-in to unsafe Rust when using
\lstinline{FinalizerUnchecked<T>}, since incorrect use is dangerous,
but Rust structs cannot be marked as unsafe directly. Instead we mark
the struct's constructor (\lstinline{FinalizerUnchecked::new}) as
unsafe. Note that, unlike auto traits, programmers can recreate
\lstinline{FinalizerUnchecked<T>} in their own code: we provide
it both for convenience and as a standard, recognisable, means of informing
code readers about the original programmer's intentions.


\subsection{Putting it all together}

\begin{algorithm}[t]
  \captionof{algorithm}{Finaliser safety analysis}
  \label{alg:fsa}
  \begin{algorithmic}[1]
    \Function{FinaliserSafetyAnalysis}{\textit{func}}
      \ForEach {\textit{basic\_block} $\in$ \textit{func}}
            \State $t \gets$ \textit{basic\_block.terminator}
            \If {\NOT \Call{IsGcConstructorCall}{$t$}}
                \State \textbf{continue}
            \EndIf
            \State \textit{ty} $\gets$ \Call{GetTyOfGcValue}{$t$}
            \If {\Call{isFinaliserUnchecked}{\textit{ty}} \OR \NOT \Call{RequiresFinaliser}{\textit{ty}}}
              \State \textbf{continue}
            \EndIf
            \If { \NOT \Call{ImplementsTrait}{\textit{ty}, \textit{ReferenceFree}}}
            \State \Call{EmitReferenceError}{}
            \Else
            \ForEach {$drop\_method \in$ \Call{GetDropGlue}{\textit{ty}}}
              \If { \NOT \Call{IsMIRAvailable}{\textit{drop\_method}}}
                  \State \Call{EmitFinaliserUnsafeError}{}
              \EndIf
              \State \Call{CheckDropMethodSafety}{\textit{drop\_method}}
            \EndFor
            \EndIf
      \EndFor
\EndFunction
\State{}
    \Function{CheckDropMethodSafety}{\textit{drop}}
    \State $ty \gets$ \Call{GetTyOfDropValue}{\textit{drop}}
    \If {\Call{IsFinaliserSafe}{\textit{ty}}}
      \State \Return
    \EndIf
      \ForEach {\textit{basic\_block} $\in$ \textit{drop}}
        \ForEach {$\textit{statement} \in \textit{basic\_block}$}
            \ForEach {$\textit{projection} \in \textit{statement}$}
              \If{\NOT \Call{IsFinaliserSafe}{\textit{projection.element}}}
                  \State \Call{EmitFinaliserUnsafeError}{}
              \EndIf
            \EndFor
        \EndFor
      \EndFor

\EndFunction
\State{}
  \Function{IsFinaliserSafe}{\textit{ty}}
    \State \Return{\Call{Impls}{\textit{ty}, $Send$} \AND {\Call{Impls}{\textit{ty}, \textit{Sync}}} \AND {\Call{Impls}{\textit{ty}, \textit{FinaliserSafe}}}}
\EndFunction
\end{algorithmic}
\end{algorithm}

\cref{alg:fsa} puts all the parts of FSA together. In essence, it iterates over
every function in \rustc's MIR and checks whether types used in a
\lstinline{Gc<T>} satisfy FSA. To simplify the presentation, the algorithm as
presented performs no caching \laurie{presumably the implementation does?!}\jake{We don't explicitly do any caching in the FSA pass, but MIR transform API does do some form of caching internally. Also the \lstinline{requires_finaliser} intrinsic does do caching}, so
a type can be checked multiple times. As the algorithm shows, the seemingly
separate parts of FSA are able to use much of the same machinery (and reuse
algorithms from earlier sections).

The \lstinline{Emit*Error} functions represent an important convenience. Rather
than just inform a user that `your drop method has not passed FSA', \ourgc
pinpoints precisely which field or line in a drop method caused FSA to fail.
\lstinline{EmitReferenceError} informs the user when a reference in a type
is used in a way that violates FSA (see~\cref{sec:fsa_rust_references}).
\lstinline{EmitFinaliserUnsafeError} informs the user when a drop method
contains code which is unsafe (e.g.~references a \lstinline{Gc<T>} type, an
opaque function, etc.). \laurie{jake: let's add a figure showing whichever the
easiest-to-grok error is as a result of running \ourgc}


\section{Performance Evaluation}
\label{sec:evaluation}

\begin{table}[t]
\begin{center}
\begin{tabular}{lll}
\toprule
  Benchmark & Version & Description \\
\midrule
  \binarytrees & Debian CLBG \binarytreesversion  & Heap allocation microbenchmark \\
  \grmtools & \grmtoolsversion  & Lexer / parser library \\
  \minimoka & \minimokaversion  & Concurrent cache library \\
  \regexredux & Debian CLBG \regexreduxversion  & Regular expression matching \\
  \sws & \swsversion  & Web server\\
  \midrule
  \somrsast & git \#\somrsversion  & SOM AST VM\\
  \somrsbc & git \#\somrsversion  & SOM bytecode VM\\
  \yksom & git \#\yksomversion  & SOM bytecode VM\\
\bottomrule
\end{tabular}
\end{center}

  \vspace{5pt}
  \caption{Our suite of benchmarks: we take these Rust programs and alter them
  to use different memory allocation strategies (\ourgc, \lstinline{Rc<T>},
  etc.). The top half of the table shows a traditional suite of benchmarks. The
  bottom half shows three SOM (a programming language) VMs. For all three SOM
  VMs, we use the same SOM version of the `Are We Fast Yet?' benchmark suite
  (git\#\awfyversion)\cite{marr16cross}; each SOM VM is thus a proxy for 26 additional benchmarks.}
\label{tab:benchmarks}
\end{table}

To understand the performance of \ourgc, and the various aspects that make it
up, we carried out several performance experiments. In this section we explain
our methodology and our experimental results.


\subsection{Methodology}

We ran four main experiments:

\vspace{6pt}
\begin{tabular}{ll}
  \Egcrc & the relative performance of \texttt{Gc<T>} over other allocation strategies (e.g.~\texttt{Rc<T>}) \\
  \Eelision & the performance gains of finaliser elision \\
  \Eprem & the costs of premature finaliser prevention \\
  \Epremopt & the performance gains from optimising premature finaliser prevention
\end{tabular}
\vspace{10pt}

There is no existing benchmark suite for GCs for Rust. Even if such a suite did exist, it
may not have been suitable for our experiment because in experiment \Egcrc we
want to compare programs a memory strategy such as \lstinline{Rc<T>} against
\lstinline{Gc<T>}. We searched through tens of the most popular
Rust libraries on \lstinline{crates.io} (the \emph{de facto} standard Rust
package system) looking for suitable candidates. Several that initially
appeared suitable relied on unusual and/or unsafe features of their memory
strategy that would have taken unreasonable time to adapt (\emph{RustPython},
\emph{Boa}, \emph{Rkyv}) while other popular crates did not seem like suitable
candidates as they did not make use of other shared ownership strategies (e.g.
\lstinline{Rc<T}) in their performance critical areas.

\cref{tab:benchmarks} shows our eventual benchmark suite. \binarytrees and \regexredux
are well-known microbenchmarks. \binarytrees is particularly allocation intensive.
The remaining benchmarks are `real' libraries and programs: \grmtools is a
parsing library which uses \lstinline{Rc<T>} extensively; \minimoka
\laurie{uses what?}; \sws is built on top of the \emph{Hyper} HTTP library,
which itself uses the \emph{tokio} async runtime and uses \lstinline{Arc<T>}
extensively.

Our suite also includes three SOM VMs. SOM is a small, but complete,
Smalltalk-esque language with a wide variety of implementations. \somrsast and
\somrsbc are existing implementations, both relatively faithful ports of a Java
SOM VMs into Rust that use \lstinline{Rc<T>}. \yksom is a from-scratch rewrite
for this paper that is designed to be more idiomatic and higher performance.
Crucially, the SOM VMs enable us to run the same `Are We Fast Yet?'
\cite{marr16cross} benchmark suite, turning what appears to be 1 benchmark into 26
(mostly micro) benchmarks.

Our benchmark suite includes programs which use the following memory
strategies: \lstinline{Arc<T>}, \lstinline{Rc<T>}, \rustgc (an existing GC for
Rust), and \typedarena (an arena library). We ported \binarytrees to each of
these memory strategies and \ourgc. For all the other benchmarks, we ported
them from their existing memory strategy to \ourgc.

We ran each benchmark in our suite 30 times reporting 99\% confidence intervals.
intervals.

\jake{We replaced the allocator with the \boehm for every benchmark so that we
are comparing the strategies only. We should make a note of this in our threats
to validity.}

\jake{\binarytrees, \regexredux and the SOM VMs all use rebench\cite{rebench18marr}}


\subsection{Results}

\begin{table}[t]
\scalebox{0.7}{%
  \input{table_overview}
}
  \vspace{5pt}
  \caption{Overview of results across all benchmarks \jake{TODO: grmtools and
  mini-moka}}
  \label{table:overview}
\end{table}

\autoref{table:overview} shows the results for this experiment. The results
shows that for \binarytrees (an allocation heavy benchmark)
\textsc{Typed-arena} was the fastest as it never performs any deallocation
during the benchmark run, it simply deallocates all memory at the end.

\rustgc performs poorly for two reasons. First, it uses a form of reference
counting to track the roots for each garbage collected object. Second, it has a
naive implementation of the mark-sweep algorithm and does not use parallel
collector threads.

\begin{figure}[t!]
    \centering
    \includegraphics[width=1\textwidth]{graphs/som_rs_perf.pdf}
    \caption{Results from the \somrs micro-benchmark experiment, where the SOM
    benchmark suite is run to compare two configurations of \somrs: \somrsrcbdwgc, where SOM objects are managed with RC but use the BDWGC's allocator with GC disabled; and \somrsgc, where SOM objects are managed using \ourgc's GC library, which uses the BDWGC's allocator. Each benchmark is run for 100 process
    executions, where the error bars represent 99\% confidence intervals.}
\label{graph:som_rs_finalisers}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=1\textwidth]{graphs/som_rs_finalisers.pdf}
    \caption{Results of a performance of \somrs using two configurations: naive
    finalisation (where no optimisation is performed); and \ourgc's finaliser
    elision optimisation (where finalisers which are used only to deallocate
    memory are removed). Each benchmark is run for 30 process executions, where
    the error bars represent 99\% confidence intervals.}
\label{graph:som_rs_finalisers}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=1\textwidth]{graphs/yksom_finalisers.pdf}
    \caption{Results of a performance of \yksom using two configurations: naive
    finalisation (where no optimisation is performed); and \ourgc's finaliser
    elision optimisation (where finalisers which are used only to deallocate
    memory are removed). Each benchmark is run for 30 process executions, where
    the error bars represent 99\% confidence intervals.}
\label{graph:yksom_finalisers}
\end{figure}

\begin{figure}[t!]
    \centering
    \includegraphics[width=1\textwidth]{graphs/som_rs_barriers.pdf}
     \caption{Results showing the performance of early finaliser prevention on
     \somrs, which uses three configurations: \textit{None} where there are
     no compiler barriers (which is unsound); \textit{All}, where every
     single \lstinline{Gc} reference has a corresponding barrier; and
     \textit{None}, where barriers can be optimised away where \ourgc is
     certain they are unnecessary. Each configuration is compared using a
     subset of benchmarks on the Rebench benchmarking suite for 30 process
     executions, where I report 99\% confidence intervals.}
\end{figure}

\section{Threats to validity}

We cannot state with certainty that the solutions we presented for finalisers'
problems are complete or correct. We have introduced a number of new tests
\laurie{how many?} into \ourgc's test suite to target specific problems. We
have ported a number of existing programs to use \ourgc, since some GC problems
only manifest at scale. However, we could undoubtedly have performed much wider
testing, investigated fuzzing, and so on: it is inevitable that there will be
bugs in \ourgc that are entirely our fault (i.e.~are not simply inherited from
\rustc or \boehm).

Our definition of the problems, the design of our solutions, and the way we
implemented them are presented in a fairly informal manner. Though we must
admit that this partly reflects our backgrounds, a formal definition, let alone
verification, would be challenging for two reasons. First, the problematic
aspects of GC we tackle in this paper have resulted from careful analysis of
running systems (e.g.~\cite{boehm03destructors}): to the best of our knowledge,
no formalism of GC exists which truly covers these aspects. We suspect this is
a mixture of a lack of research on this problem and also the challenging
temporal aspects, which may not be an easy fit with many existing formalisms.
Perhaps the closest analogue is the evolving research literature on memory
models which, in a sense, modern GC is a superset of. Second, at the time of
writing, Rust's semantics remain somewhat imprecise and incomplete, though this
situation is gradually improving.

Any performance judgements we make are necessarily contingent on our particular
benchmark suite. We cannot say, for example, that finaliser elision will always
improve performance by the \laurie{X\%} we see in our experiment: there
undoubtedly exist reasonable, non-pathological, programs which will gain more
or less from such factors. It would help if there was a more widely accepted
set of programs to serve as a benchmark for GC in Rust. Since the benchmark
suite in this paper is the largest for any GC in Rust \laurie{is that true of
Bronze?}, it may serve as a partial basis for such a suite in the future.


\section{Related work}
\label{sec:related_work}

Throughout Rust's history, there have been several attempts to introduce some
form of tracing garbage collection~\citep{felix15specifying, felix16roots,
manish16gc}. In fact, early versions of Rust explored using a form of this as a
first class feature of the language through the use of \emph{managed pointers}
(with the syntax \lstinline{@T}).\jake{cite: } This was removed early in Rust's
development before the first stable release \jake{cite removal commit
\lstinline{https://github.com/rust-lang/rust/commit/ade807c6dcf6dc4454732c5e914ca06ebb429773}}.

\citep{rustbacon} is a Rust library implementation of~\citep{bacon01concurrent}
which provides reference counting with tracing cycle collection. Like \ourgc it
introduces a user-visible type (\lstinline{Cc<T>}) for managing memory. The
underlying memory of a \lstinline{Cc<T>} object is reference counted, however,
when the reference count is decremented to a non-zero value, it is added to a
worklist so that it can later be checked for potential cycles (by a user
invoked \lstinline{collect_cycles} function). This performs a local trace .

Unlike \ourgc, destruction in \citep{rustbacon} is deterministic: it occurs as
soon as an object's last owner is gone; in the case of cyclic garbage, this
means after the user calls \lstinline{collect_cycles}. However, like \ourgc it
relies on the \lstinline{Drop} trait for destruction and does not implement
it's own \lstinline{Finalise} trait. \lstinline{Cc<T>} uses a \lstinline{T: 'static} bound, which prevents it from containing any regular rust references.
This prevents the trapdoor reference in finalisers problem explained in
\jake{section FSA}.

There are several advantages of \citep{rustbacon} over \ourgc: first, it is
purely library based, requiring no modifications to the Rust compiler to work;
second, for non-cyclic data, values will be dropped immediately like
\lstinline{Rc}; third, the deterministic nature of drop methods means that it
does not need to be run on a separate thread, eliminating a whole class of
synchronisation and concurrency errors present in traditional tracing-based
finalisation \jake{cite fsa section}.

It has several limitations when compared to \ourgc. First, it is single-thread
(though a concurrent cycle detection algorithm is theoretically
possible~\citep{bacon01concurrent}). Second, a \lstinline{Trace} trait,
detailing how to traverse an objects fields during cycle detection must be
manually implemented for any \lstinline{T} used inside a \lstinline{Cc}. This
means that it cannot be used with types from external crates without the
new-type workaround. Third, since drop methods are called on cyclic garbage,
drop methods which dereference fields of other \lstinline{Cc} objects will
result in a crash at runtime. \ourgc, on the other hand, will prevent such
programs from compiling with FSA.

In \autoref{sec:destructor challenges}, we introduced the most well-known tracing
GC option in Rust \citep{rustgc}. \jake{That section already discusses the
finalisation differences, so I won't repeat them here} The API for \rustgc is
similar to \ourgc, with the notable exception that \lstinline{Gc} in \rustgc
does not implement the \lstinline{Copy} trait. This means that in order to
obtain additional pointers to garbage-collected objects, the \lstinline{Gc}
must be cloned.

\laurie{what is the practical difference between \rustbacon and \rustgc?
from the description they sound identical from a user's perspective} \jake{the main difference is that a cycle collection must be explicitly invoked by the user for \rustbacon}
\rustgc is implemented as a hybrid form of reference counting and tracing GC.
There is no mechanism for scanning the stack for roots as in traditional GC, so
roots are tracked using reference counting, with a mark-sweep then performed
from these roots. Like \ourgc, \lstinline{Gc} references in \rustgc point to an
underlying \lstinline{GcBox}. However, in \rustgc, this \lstinline{GcBox}
maintains a count of all of its roots. \autoref{lst:rustgc_roots} shows how this
count is updated as references are used. During a collection, the
\lstinline{GcBox}'s on the heap are enumerated, and those with a non-zero root
count are used as roots to begin marking. Like \rustbacon, \rustgc traces
through objects by requiring types used in \lstinline{Gc} to implement a
\lstinline{Trace} trait, which has a \lstinline{trace} method called during
marking to traverse and mark objects during a collection.

\rustgc makes implementing \lstinline{Trace} easy by providing a macro
implemention, where types can be annotated with \lstinline{#[derive(Trace)]} and
have it implemented automatically. It uses its own type, \lstinline{GcCell} in
order to support interior mutability as a \lstinline{RefCell} cannot be used
with \rustgc. The \lstinline{GcCell} provides additional support for rooting and
unrooting objects across a borrow as they are mutated inside the \lstinline{Gc}.
It provides a similar API to the user as \lstinline{RefCell}.

Unlike \ourgc, objects are finalised by implementing a \lstinline{Finalise}
trait. Though this reduces much of the complexity that \ourgc needs in order to
support calling \lstinline{T::drop} from a finaliser or destructor context,
\rustgc requires the programmer to ensure that a finaliser implementation is
present for any type that may need to call \lstinline{Drop} on any of its
component types. It is not easy to know which of these component types may need
dropping, and forgetting to do so can cause memory leaks.

The \emph{Bronze} collector is an optional GC implementation for Rust which was
designed address usability concerns with Rust's borrow
semantics~\citep{coblenz21bronze}. It was
designed alongside an empirical study which measured how long it took students
to complete a variety of Rust tasks by using standalone Rust, and Rust with
Bronze for managing memory.

Bronze bases much of its implementation on \rustgc but with two key differences.
First, it tracks roots to GC objects by using a modified version of the Rust
compiler. Bronze's rustgc implementation inserts calls to LLVM's
\lstinline{gc.root} intrinsic at function entries in order to generate
stackmaps. When a GC call is requested, Bronze iterates over the stackmaps
generated its current call stack in order to locate the roots for garbage
collection. However, Bronze does not implement this for transitive references
from arbitrary objects. In other words, if a \lstinline{Gc<T>} exists as a field
inside another object instead of directly on the stack, it is not tracked
as a root for garbage collection.

The second major difference between \rustgc and Bronze is that Bronze's
\lstinline{Gc<T>} type allows the programmer to dereference its underlying type
\lstinline{T} mutably more than once. \citet{coblenz21bronze} describes this
as beneficial, because it makes it easier to use than other Rust shared
ownership. However, this is fundamentally unsound, and allows programs which
violate memory safety to be written in safe Rust using Bronze.
\autoref{lst:bronze_unsound} shows an example of how this can violate memory
safety by causing a write from deallocated memory.


\subsection{How other languages deal with finalisers}

The D programming language uses a conservative mark-sweep GC for heap
allocations by default with support for opt-in explicit deallocation. Like \ourgc, D does
not specify an order for finalisers. Users can specify their own allocators for
RAII-based heap allocation using standard \lstinline{malloc}/\lstinline{free}
calls.

Oilpan, the conservative mark-sweep garbage collector in Chrome's rendering
engine, Blink, uses two levels of finalisation: full finalisation, which happen
off-thread after a GC cycle has completed but do not allow object fields to be
dereferenced; and pre-finalisers, which happen during the sweep phase, but allow
all of an objects fields to be dereferenced. Pre-finalisers are generally
avoided because of their performance overhead since they cannot be scheduled to
run on other threads and increase the stop-the-world time.


\begin{figure}[!t]
\begin{lstrustsmall}
fn main() {
    let mut gr1 = GcRef::new(vec![1u16,2,3]);
    let mut gr2 = gr1.clone();

    let ref1 = gr1.as_mut();
    let ref2 = gr2.as_mut();

    // ref1 and ref2 now reference the same object:
    ref1.push(4);
    ref2.push(5);
    ref1.push(6);

    let ref1elem0 = ref1.get_mut(0).unwrap();
    // Force reallocation of the underlying vec
    ref2.resize(1024, 0);
    // Now this writes to deallocated memory
    *ref1elem0 = 42;
}
\end{lstrustsmall}
    \caption{An example of unsoundness in Bronze based on its ability to allow
    aliased mutable references. Here, we obtain two mutable references to the
    same underlying vector (lines 5-6), before using the second reference to
    resize the vector, which forces its backing store to be reallocated in
    memory (line 15). Later, when we try to access an element through the first
    reference, it no longer points to valid memory (line 15).
    } \label{lst:bronze_unsound}
\end{figure}

\shifgrethor~\citep{shifgrethor} is an experimental GC API for Rust which investigated a way for
potential GC implemenations to precisely identify and trace roots to GC'd
objects. \shifgrethor is therefore not a full GC library, but instead an
experimental design for how a GC could interface with the language.

The basic idea is that in order to create a \lstinline{Gc} object, it must be
created by, and exist alongside a corresponding \lstinline{Root<'root>} type on
the stack. The \lstinline{Root<'root>} can then dish out references to the
underlying \lstinline{Gc} which are tied to \lstinline{Root<'root>}'s lifetime.

\laurie{can \gcarena handle cycles? what about finalisers?}
\gcarena~\citep{gcarena} is another experimental approach at sound GC design in Rust. It was
originally developed as part of the \emph{luster} VM~\citep{luster}: an experimental Lua VM
written in Rust. Unlike \ourgc and the other approaches to GC in Rust seen so
far, \gcarena does not retrofit Rust with a GC. Instead, it provides limited
garbage collection in isolated garbage collected \emph{arenas}. Arenas carefully
guard mutator access to their objects through closures, which, when executing,
prevent the collector from running. This solves the difficult problem of finding
roots which reside on the stack: when an arena is \emph{closed} to the mutator,
no stack roots exist, so a collection can be safely scheduled. A single arena
may contain several garbage collected objects, but they cannot be
transferred between other arenas.

Because \gcarena is so different in nature to the other GCs described in this
chapter, it is difficult to compare it ergonomically to other approaches.


\section{Conclusions}

In this paper we have introduced a novel design for GC in Rust, and shown how
it solves some classical GC finaliser problems. We implemented our design in a
fork of \rustc, and showed that it has a fairly small performance overhead. We
do not claim that \ourgc is the best, final, design for GC in Rust, but it does
show how much can be achieved if one is willing to adjust and extend the
language design and, in particular, \rustc.

\bibliographystyle{ACM-Reference-Format}
\bibliography{bib}

\clearpage

\appendix

\section{Algorithms}

In this appendix, we show more formal versions of the algorithm descriptions
from the main body of the paper for those who may benefit from them.

\begin{figure}[b]
\begin{algorithmic}
\Function{RemoveElidableDrops}{$func$}
      \ForEach {$basic\_block \in func$}
            \If {\Call{IsDropTerminator}{$basic\_block.terminator.kind$}}
                \State $ty \gets$ \Call{GetTypeOfDroppedValue}{$block.terminator$}
                \If {\Call{IsGcType}{$ty$}}
                    \If {\NOT \Call{RequiresFinaliser}{$ty$}}
                        \State \Call{ReplaceTerminator}{$basic\_block$}
                    \EndIf
                \EndIf
            \EndIf
      \EndFor
\EndFunction
\Function{ReplaceTerminator}{$basic\_block$}
    \State $drop\_func \gets$ \Call{GetDropFunc}{$basic\_block.terminator$}
    \State $last\_block \gets$ \Call{GetLastBasicBlock}{$drop\_func$}
    \State $block.terminator \gets last\_block.terminator$
\EndFunction
\end{algorithmic}
% \end{algorithm}
  \captionof{algorithm}{The MIR pass for removing premature finaliser barriers
  for types with elided finalisers. This pass is registered inside \rustc,
  where it is invoked on all \textit{func}s in the program. The
  \textit{RemoveElidableDrops} iterates each basic block in a function in order
  to inspect whether the terminator is a call to a drop method as these are the
  only terminators of interest in this pass. If a ``drop terminator'' is found,
  then we check the type of the value being dropped. If the type of the value
  being dropped is a \lstinline{Gc<T>}, and its finaliser can be elided, then
  the drop terminator can be replaced. We can then replace these terminators by
  ``leaping over'' the drop method and patching it to the next basic block in
  the control flow.}
  \label{alg:barrier_removal}
\end{figure}

\end{document}
