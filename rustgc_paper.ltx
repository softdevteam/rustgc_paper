%&rustgc_paper_preamble
\endofdump

\begin{document}

\begin{abstract}
\noindent Rust is a non-Garbage Collected (GCed) language, but the lack of GC
makes expressing data-structures that require shared ownership awkward,
inefficient, or both. In this paper we explore a new design for, and implementation of GC in
Rust, called \ourgc. Unlike previous
approaches to GC in Rust, \ourgc maps existing Rust destructors to
finalizers: this makes GC in Rust natural to use but introduces surprising
soundness, performance, and ergonomic problems. \ourgc provides solutions for
each of these problems.
\end{abstract}

\maketitle


\section{Introduction}

\begin{figure}[t]
\lstinputlisting[language=Rust, firstline=6, basicstyle=\footnotesize\ttfamily]{listings/first_example.rs}
\captionof{lstlisting}{An \ourgc example, showing use of the \lstinline{Gc<T>}
  type and destructors as finalizers. We create a type \lstinline{GcNode} which
  models a graph: it stores an 8 bit integer value and a reference (possibly
  \lstinline{None} (i.e.~`null'), via Rust's standard \lstinline{Option} type) to a neighbouring node
  (line 1). We add a normal Rust destructor which \ourgc is able to use as a
  finalizer when \lstinline{GcNode} is used inside \lstinline{Gc<T>} (line 2).
  Inside \lstinline{main} we create the first GCed node in the graph (line 5).
  We use Rust's normal \lstinline{RefCell} type to allow the node to be mutated
  (using the \lstinline{RefCell::borrow\_mut} method to dynamically detect mutation that
  would undermine Rust's static borrow checker rules)
  and a cycle created directly back to itself (line 6). We then create a second cyclic graph (lines 7
  and 8), immediately assigning it to the \lstinline{gc1} variable (line 9):
  note this copies, rather than moves, the \lstinline{Gc<T>}.
  Doing so means that the first cyclic graph \lstinline{GcNode\{value: 1, ..\}}
  is no longer reachable, so when we force a collection (line 10) that node
  can be recognised as collectable. Its finalizer is then scheduled to be run, causing
  \lstinline{drop 1} to be printed out at a later point; when it has completed the GC
  heap memory can be reclaimed. The print statement outputs \lstinline{2 2} (line
  11).}
\label{fig:first_example}
\end{figure}

Amongst the ways one can classify programming languages are whether they
are Garbage Collected (GCed) or not: GCed languages enable implicit memory management;
non-GCed languages require explicit memory management (e.g~\lstinline{C}'s \lstinline{malloc} /
\lstinline{free} functions). Rust's use of affine types~\citep[p.~5]{pierce04advanced}
and ownership does not
fit within this classification: it is not GCed but it has implicit memory management.
Most portions of most Rust programs are as
succinct as a GCed equivalent, but ownership is too inflexible to express
\emph{shared ownership} for data-structures that require multiple owners
(e.g.~doubly linked lists).
Workarounds (e.g.~reference counting) impose an extra burden on the programmer,
make mistakes more likely, and often come with a performance penalty.

In an attempt to avoid such problems, there are now a number of GCs for Rust
(e.g.~\cite{manish15rustgc, coblenz21bronze, gcarena, boa, shifgrethor}). Most
introduce a user-visible type \lstinline{Gc<T>} which takes a value
of type \lstinline{T}, moves that value to the GC heap, and returns a wrapper around
a pointer to the moved value. \lstinline{Gc<T>} can be \emph{cloned} (i.e.~duplicated) and
\emph{dereferenced} to \lstinline{T} at will by the user. When no
\lstinline{Gc<T>} wrappers pointing to a value on the GC heap
can be found, indirectly or directly, from the
program's \emph{roots} (e.g.~variables on the stack, etc.),
then the GC heap memory can be reclaimed.

It has proven hard to find a satisfying design and implementation for a GC for
Rust, as perhaps suggested by the number of different attempts to do so.
We identify two fundamental challenges
for GC for Rust: how to give \lstinline{Gc<T>} a familiar, idiomatic, complete
API; and how to make \emph{finalization} (i.e.~the code that is run just before a
value is collected by the GC) safe, performant, and ergonomic. We show that
\emph{conservative} GC (i.e.~treating each reachable machine word as
a potential pointer) is necessary and sufficient to solve the API challenge,
but the finalization challenge is more difficult.

In existing GCs for Rust, if a user needs values of type \lstinline{T} to cause a
finalizer to run, then the user must manually implement a finalizer.
Not only do most finalizers end up duplicating
existing \emph{destructors} (i.e.~code which is run just before a value is
reclaimed by Rust's implicit memory management) but this makes it impossible to
provide finalizers for types in external libraries.

The obvious solution to this problem is to allow existing Rust destructors to
be automatically used as finalizers. However, no existing GC for Rust does
this; in a close cousin of our work,
a GC proposal for C++, this approach was ruled out due to
seemingly insoluble problems~\cite[p.~32]{boehm09garbage}. We place these problems into four
categories:
(1) finalizers are prohibitively slower than destructors;
(2) finalizers can be run prematurely;
(3) running finalizers on the same thread as a paused mutator can cause race conditions and deadlocks;
(4) some safe destructors are not safe finalizers.
All are, at least to some degree, classical GC problems; all are exacerbated
in some way by Rust; and none, with the partial exception of (2), has
existing solutions.

We introduce novel solutions to
these problems by making use of some of Rust's unusual static guarantees
We thus gain not just a better GC for
Rust, but also solutions to open GC problems. Our solutions, in order, are:
(1) \emph{finalizer elision} statically optimises away finalizers if the
underlying destructor duplicates work the GC does anyway.
(2) \emph{premature finalizer prevention} automatically inserts barriers to prevent
optimisations or register allocation from `tricking'
the GC into collecting values before they are dead;
(3) we run finalizers on a separate thread; and
(4) \emph{finalizer safety analysis}
extends Rust's static analyses to reject programs whose destructors are not
provably safe to be used as finalizers.

These solutions are implemented as part of \ourgc, a new GC for Rust:
an example of its use is shown in \cref{fig:first_example}.
Although \ourgc is not production ready, it has good enough performance
(across a number of benchmarks, its performance is \jake{geomean over whole suite}) and
other polish (e.g.~good quality error messages) that we believe it shows
a plausible path forwards for those who may wish to follow it. Furthermore,
although \ourgc is necessarily tied to Rust, we believe that most of the
techniques in this paper, particularly those related to finalization, are
likely to generalise to other ownership-based languages.

This paper's high-level structure is: background (\cref{sec:background});
\ourgc's design (\cref{sec:alloy_design}); destructor and finalizer challenges
and solutions (\cref{sec:destructor challenges,sec:elision,sec:premature_finalize_prevention,sec:fsa}); and evaluation
(\cref{sec:evaluation}). The first three parts have the challenge that our work
straddles two areas that seem almost mutually exclusive: GC and Rust. We have
tried to provide sufficient material for readers expert in one of these
areas to gain adequate familiarity with the other, but we explicitly encourage
readers to skip material they are already comfortable with.


\section{Background}
\label{sec:background}

\subsection{Does Rust need a GC?}

\begin{figure}[t]
\lstinputlisting[language=Rust, firstline=5, basicstyle=\footnotesize\ttfamily]{listings/rc_example.rs}
\captionof{lstlisting}{
  A version of~\cref{fig:first_example} using Rust's standard reference
  counting type \lstinline{Rc<T>}. To avoid memory leaks we use \emph{weak}
  references between nodes (line 1). We again create two cyclic graphs (lines
  6--9) using \lstinline{Rc::downgrade} to create weak references (lines 7 and
  0). Since \lstinline{Rc<T>} is not copyable, we must use a manual
  \lstinline{clone} call to have both the \lstinline{rc1} and \lstinline{rc2}
  variables point to the same cyclic graph (line 10). Accessing a neighbour
  node becomes a delicate dance requiring upgrading the weak reference (line 11).
  The need to downgrade \lstinline{Rc<T>} to \lstinline{Weak<T>} and upgrade
  (which may fail, hence the \lstinline{unwrap}) back to \lstinline{Rc<T>}
  creates significant extra complexity relative to~\cref{fig:first_example}: compare
  line 11 in \cref{fig:first_example} to (the much more complex) lines 10-12
  in this \lstinline{Rc} example.
}
\label{fig:rc_example}
\end{figure}

Rust uses affine types and \emph{ownership}
to statically guarantee that: a \emph{value} (i.e.~an instance of a type) has a
single owner (e.g.~a variable); an owner can \emph{move} (i.e.~permanently
transfer the ownership of) a value to another owner; and
when a value's owner goes out of scope, the value's destructor
is run and its backing memory reclaimed. An owner can pass \emph{references} to a value
to other code, subject to the following static restrictions: there can be
multiple immutable references (`\lstinline{&}') to a value or a single
mutable reference (`\lstinline{&mut}'); and references cannot outlast the owner.

These basic rules mean that many Rust programs are as succinct as their equivalents
in GCed languages, since no explicit memory management is required. This
suggests that the search for a good GC for Rust may be quixotic:
intellectually stimulating, but of no practical value.

However, there are many programs which need to express data structures which
are sound but which do not fit into the restrictions of affine types and
ownerships. These are often described as `cyclic data-structures', though
that sometimes gives the incorrect impression that only data structures
such as linked lists are of interest. In reality, programs as diverse as
interpreters for dynamically typed languages have need to use such types,
so we prefer the slightly more abstract term `shared ownership'.
(e.g.~interpreters for dynamically typed languages
Rust cannot directly express
such programs, forcing programmers to use various workarounds.

Probably the most common workaround is the reference counting type \lstinline{Rc<T>} in Rust's
standard library. For many data-structures, reference counting is a reasonable
solution, but using it for values which may have shared ownership requires
juggling strong and weak counts. This complicates the program
(see~\cref{fig:rc_example}) and makes
it easy for values to live for shorter or longer than intended.

Another common workaround is to store values in a vector and use
integer indices into that vector. Such indices are then morally closer to
machine level pointers than normal Rust references: the indices can become
stale, dangle, or may never have been valid in the first place. The programmer
must also manually deal with issues such as detecting unused values,
compaction, and so on. In other words, such workarounds force the programmer
to write a partial GC themselves. A variant on this idea are
\emph{arenas}, which gradually accumulate multiple values but free all of them in one go: values
can no longer be reclaimed too early, but, equally, individual values cannot be
reclaimed until all values are determined to be unneeded.

A type-based approach is
\lstinline{GhostCell}~\cite{yanovski21ghostcell}, which uses `branding' to
statically ensure that only one part of a program can access a
shared ownership data-structure at a time.
However, this implicitly prevents multiple owners (e.g.~in different threads)
from reading or mutating different parts of the structure.

Although it is easily overlooked, some workarounds (e.g.~\lstinline{Rc<T>})
rely on using \emph{unsafe} Rust (i.e.~parts of the language, often involving
pointers, that are not fully statically checked by the compiler). It is reasonable
to assume that widely used code, even if technically unsafe, has been pored
over sufficiently that it is mostly, perhaps even wholly, reliable in practise. It
is less reasonable to assume that `new' solutions that a programmer implements using
unsafe Rust will immediately reach the same level of reliability. Our experience
is that most Rust programmers will avoid writing new unsafe code if they can, even
if doing so might in the long-term lead to a better system.

While we do not believe that every Rust program would be improved by GC, the
variety of workarounds already present in Rust code suggests that a substantial
subset might benefit from GC.


\subsection{GC terminology}

GC is a venerable field and has accumulated terminology that can seem
unfamiliar or unintuitive. We mostly use the same terminology
as~\cite{jones16garbage}, the major parts of which we define here.

A program which uses GC is split between the \emph{mutator} (the user's program) and
the \emph{collector} (the GC itself). At any given point in time, a particular thread is either
running as a mutator or a collector. In our context, all threads
run as a collector at least sometimes, with some threads always running as a collector.
Tracing and reclamation is performed during a \emph{collection} phase. In the context of
this paper, collections are \emph{stop-the-world}, where all mutator threads
are paused while collection occurs.

A \emph{tracing} GC is one that scans memory looking
for reachable objects from a program's roots: objects that are not reachable
from the roots can then be \emph{reclaimed}. In contrast, a reference counting GC does
not scan memory, and thus cannot free objects that form a cycle. As is common
in most GC literature, henceforth we use `GC' to mean `tracing GC'.

We refer to memory which is allocated via \lstinline{Gc<T>} as being on
the \emph{GC heap}. We use the term `GC value' to refer both to the pointer wrapped in a
\lstinline{Gc<T>} and the underlying value on the GC heap, even though multiple
pointers / wrappers can refer to a single value on the heap, unless doing so
would lead to ambiguity.

We use `\ourgc' to refer to the combination of: our extension to the Rust
language; our modifications to the \lstinline{rustc} compiler; and our
integration of the Boehm-Demers-Weiser GC (\boehm) into the runtime of programs
compiled with our modified \lstinline{rustc}.


\section{\ourgc: Design and Implementation}
\label{sec:alloy_design}

In this section we outline \ourgc's basic design and implementation choices --
the rest of the paper then goes into detail on the more advanced aspects.


\subsection{Basic Design}
\label{sec:basic design}

\ourgc provides a \lstinline{Gc<T>} type that exposes an API modelled on the
reference counting type \lstinline{Rc<T>} from Rust's standard library, because
\lstinline{Rc<T>}: is conceptually
similar to \lstinline{Gc<T>}; widely used in Rust code, and its API
familiar; and that API reflects long-term experience about what Rust programmers
need from such a type.

When a user calls \lstinline{Gc::new(v)}, the value \lstinline{v} is
moved to the GC heap: the \lstinline{Gc<T>} value returned to the user is a
simple wrapper around a pointer to \lstinline{v}'s new address. \lstinline{Gc<T>}
can dereferenced at will to \lstinline{T}. The same underlying GCed value
may thus have multiple partly overlapping references active at any point.
To avoid undermining
Rust's ownership system, this means that dereferencing a \lstinline{Gc<T>} must
produce an immutable (i.e.~`\lstinline{&}') reference to the underlying value.
If the user wishes to mutate the underlying value, they must use other Rust
types that enable \emph{interior mutability} (e.g.~\lstinline{RefCell<T>} or
\lstinline{Mutex<T>}).

One feature that \ourgc explicitly adopts is \lstinline{Rc<T>}'s
ability to be transformed into a raw pointer (\lstinline{into_raw}) and
back (\lstinline{from_raw}). Though many programmers do not directly
encounter these functions, they are a crucial part of the link between Rust's high and
low-level features (e.g.~being used for the C Foreign Function Interface
(FFI) alongside the ability to cast Rust references to pointer types and back).
We believe that a viable GC for Rust must include this same
ability, but doing so has a profound impact because Rust allows raw pointers to be
converted to the integer type \lstinline{usize} and back\footnote{Although
it is outside the scope of this paper, it would arguably
be preferable for Rust to have different integer types for `data width' and
`address'. Modern C, for example, does this with the \lstinline{size_t} and
\lstinline{uintptr_t} types respectively. Rust now has a provenance lint to
nudge users in this general direction, but the \lstinline{as}
keyword still allows arbitrary conversions.}.

\label{conservative_gc}
Having acknowledged that pointers may end up disguised as integers, it is then
inevitable that \ourgc must be a conservative GC: if a machine word's integer
value, when considered as a pointer, falls within a GCed block of memory,
then that block itself is considered reachable (and is thus transitively scanned).
Since a conservative GC cannot know if a word is really a pointer, or just happens to be a sequence of
bits that happens to look like a valid pointer, this over-approximates the
\emph{live set} (i.e.~the blocks that the GC will not reclaim). However, the
most extensive study we know of suggests the false detection rate in Java
programs is under 0.01\% of live objects~\cite{shahriyar14fast}, so it is
unlikely to be a problem in practise.

Conservative GC occupies a grey zone in programming language semantics: in most
languages, and most compiler's internal semantics, conservative GC is, formally
speaking, unsound; and furthermore some languages (including Rust) allow
arbitrary `bit fiddling' on pointers that temporarily
obscures the address they are referring to. Despite this, conservative GC is widely used,
including in the two most widespread web browsers: Chrome uses it in its Blink
rendering engine~\citep{ager13oilpan} and Safari uses it in its JavaScript VM
JavaScriptCore~\citep{pizlo17riptide}. Even in 2024, we lack good alternatives
to conservative GC: there is no cross-platform API for precise GC; and while
some compilers such as LLVM provide some support for GC
features~\cite{llvm14statepoints}, we have found them incomplete and buggy.
Despite the potential soundness worries, conservative GC thus remains a widely
used technique.

\label{gc_is_copyable}
Conservative GC enables \ourgc to make a useful ergonomic improvement over
most other GCs for Rust whose \lstinline{Gc<T>} is only \emph{cloneable}. Such types can be duplicated, but doing
so requires executing arbitrary user code. To make the possible run-time cost of this clear, Rust has
no direct syntax for cloning: users must explicitly call \lstinline{Rc::clone(&x)}
to duplicate a value \lstinline{x}. In contrast, since \ourgc's \lstinline{Gc<T>} is just a wrapper around a pointer it
is not just cloneable but also \emph{copyable}: duplication only requires copying
bytes (i.e.~no arbitrary user code need be executed). Copying is implied by assignment,
reducing the need for a function call that cloning requires entirely\footnote{The lengthier
syntax \lstinline{y = Gc::clone(&x)} is available, since every copyable type is
also cloneable.}. This is not just a syntactic convenience but also reflects an underlying
semantic difference: duplicating a \lstinline{Gc<T>} in \ourgc is is a cheaper and simpler operation
than in most other GCs for Rust (which often rely in part on reference counting).


\subsection{Basic Implementation}

The most visible aspect of \ourgc is its fork, and extension of, the standard
Rust compiler \rustc. We forked \rustc~\rustcversion and have
added or changed approximately 3,150 Lines of Code (LoC). Users must opt-in
to GC by enabling the allocator and assigning it to an arbitrarily-named variable:

\begin{lstlisting}[language=Rust, numbers=none, basicstyle=\footnotesize\ttfamily]
#![feature(gc)] use std::gc::GcAllocator;
#[global_allocator] static A: GcAllocator = GcAllocator
\end{lstlisting}

\ourgc uses \boehm as the underlying conservative GC, as we were
able to make some necessary changes to it with relative ease. However,
\ourgc does not fundamentally rely on \boehm specifically, and our
work is likely to apply to other conservative GCs with minimal changes.

We made the following changes to \boehm. First, we disabled \boehm's parallel collector
because, for reasons we don't fully understand, it worsens \ourgc's
performance. Second, \boehm cannot scan pointers stored in thread locals
because these are platform dependent. Fortunately, \rustc uses LLVM's
thread local storage implementation, which stores such pointers in the
\lstinline{PT_TLS} segment of the ELF binary: we modified \boehm to scan
this ELF segment during each collection. Third,
\boehm normally dynamically intercepts thread creation calls so that it can
then can scan their stacks, but (for bootstrapping
reasons) it is unable to do so in our context: we explicitly changed \ourgc
to register new threads with \boehm.

We made one conceptually larger -- though only 60LoC -- change to \boehm, to run all finalizers on a
separate thread (see~\cref{sec:general_challenges,sec:fsa_finalizer_thread} for
motivation). We lazily create a thread dedicated to this once the collector has
first identified objects that need finalizing. The finalizer thread then runs
until the end of the program waiting for further work;
the collector notifies the finalizer thread of additional work via a condition
variable.


\section{Destructors and Finalizers}
\label{sec:destructor challenges}

In many GCed languages, `destructor' and `finalizer' are used as synonyms, as
both terms refer to code run when a value's lifetime has ended. In existing GCs
for Rust, these two terms tend to refer to highly related, but irritatingly
different, concepts; and, as we will see later, in \ourgc, finalizers are best
thought of as a subset of destructors.

When a value in Rust is \emph{dropped} (i.e.~the value's owner went out of lexical
scope) its destructor is automatically run. Rust destructors are formed of two
parts, run in the following order: a user-defined \emph{drop method}; and
automatically inserted \emph{drop glue}. Drop methods are optional; users
can provide one for a type by implementing the \lstinline{Drop} trait's \lstinline{drop}
method. Drop glue recursively calls destructors of contained types (e.g.~fields
in a \lstinline{struct}). Although it is common usage to conflate `destructor' in
Rust with drop methods, drop glue is an integral part of a Rust destructor:
we therefore use `destructor' as the umbrella term for both drop methods and drop glue.

Rust's destructors enable a style of programming that originated in C++ called RAII (Resource
Acquisition Is Initialization)~\cite[Section~14.4]{stroustrup97c++}: when a
value is dropped, the underlying resources it possesses (e.g.~file handles or heap memory)
are released. A casual perusal of Rust code will quickly show that
drop methods are used frequently and that users fairly often
implement their own drop methods.

Most existing GCs for Rust are forced to have separate notions of destructors and finalizers.
Where the former have the \lstinline{Drop} trait, the later typically have
a \lstinline{Finalize} trait. If a user type needs to be finalized then
the user must provide an implementation of the \lstinline{Finalize} trait for that type.
However, doing so introduces a number of problems: (1) external libraries are
unlikely to provide finalizers and so placing their types in a \lstinline{Gc<T>}
tends to break RAII expectations; (2) Rust's \emph{orphan
rule}~\cite[Section~6.12]{rustlangref} prevents one implementing traits for
types defined in external libraries (i.e.~unless a library's types were
designed to support \lstinline{Gc<T>}, those types cannot be directly GCed);
(3) one cannot automatically replicate drop glue for finalizers; and (4) one
cannot replicate \rustc's refusal to allow calls to the equivalent of
\lstinline{Drop::drop}.

Programmers can work around problems \#1 and \#2 in various ways. For example,
they can wrap external library types in \emph{newtypes} (zero-cost wrappers)
and implement finalizers on those instead~\cite[Section~19.3]{klabnik18rust}.
Doing so is tedious but not conceptually difficult.

Problem \#3 has partial solutions: for example, ~\cite{manish15rustgc} uses the
\lstinline{Trace} macro to generate \emph{finalizer glue} (our term for
the finalizer equivalent of drop glue) for
\lstinline{struct} fields. This runs into an unsolvable variant of problem \#2:
types in external libraries will not implement this trait and cannot be
recursively scanned for finalizer glue.

Problem \#4 is impossible to solve in Rust as-is. One cannot define a function
that can never be called --- what use would such a function have? It might seem
tempting to have the \lstinline{finalize} method take ownership of the value,
but \lstinline{Drop::drop} does not do so because that would not allow drop
glue to be run afterwards.

In summary: destruction is a core part of Rust; a GC for Rust ideally needs to
maintain most if not all of those properties for finalization; but some parts
cannot be replicated in normal user code.


\subsection{General Challenges When Using Destructors as Finalizers}
\label{sec:general_challenges}

Even if there were no Rust-specific challenges to using destructors as
finalizers, we would still face the problem that finalizers and destructors
have different, and sometimes incompatible, properties. The best overall
guide to these differences, and the resulting problems, is~\cite{boehm03destructors},
supplemented by later work by some of the same authors on support
for GC in the C++ specification~\cite{boehm09garbage}\footnote{These features
were added to the C+11 specification, but do not seem to have been implemented by
compilers. C++23 removed these features.}.

An obvious difference between destructors and finalizers is when both
are run. Where C++ and Rust define
precisely when a destructor will be run\footnote{Mostly. Rust's `temporary
lifetime extension' delays destruction, but for how long is currently
unspecified.}, finalizers run at an unspecified point in time. Although
we often assume is happens after the last reference to a GCed value is lost,
finalizers can run \emph{prematurely}, that is before the equivalent
destructor~\cite[section~3.4]{boehm03destructors}.

A less obvious difference relates to where destructors and finalizers are run.
Destructors run in the same thread as the last owner of a value.
However, running finalizers in the same thread as the last owner of the value
ran in can cause race conditions and deadlocks if one or more finalizers tries to access a resource that the mutator
expects to have exclusive access too~\cite[section~3.3]{boehm03destructors}.
When such problems affect destructors in normal Rust code, it is the clear result of programmer error, since they should
have taken into account the predictable execution point of destructors. However, since
finalizers have no such predictable execution point, there is no way for finalizers
to safely access shared resources if they are run on the same thread.
In other words, running correct destructors as finalizers can cause nondeterministic
problems. The only way to avoid this to run
finalizers on a non-mutator thread: however, not all Rust types / destructors
are safe to run on another thread.

Finally, finalization and cycles are not happy bedfellows: finalizers
can reference other GCed values that are partly, or wholly, `finalized' and may
even have had their backing memory reused. A related, but
distinct, problem is the ability of finalizers to `resurrect' values by
copying the reference passed to the finalizer and storing it somewhere.


\subsection{The Challenge of Finalizers for \ourgc}

At this point we hope to have convinced the reader of two general points: a
viable GC for Rust needs to be able to use existing destructors as finalizers
whenever possible; and that finalizers, even in existing GCs, cause
various problems.

Over time, finalizers have come to be viewed with increasing suspicion. Java,
for example, has deprecated, and intends eventually removing, per-type
finalizers: instead it has introduced deliberately less flexible per-object `cleaners', whose API
prevents problems such as object resurrection~\cite{goetz21deprecated}. It
is important to differentiate such mechanisms from the \lstinline{Finalize} trait that many existing GCs for
Rust force users to manually implement: cleaners impose restrictions
to make finalizers less problematic; existing \lstinline{Finalize} traits
do not impose any such restrictions.

Our desire that \ourgc should use existing Rust destructors as finalizers whenever
possible may seem out of reach. Indeed, in the nearest
context to our work GC for C++ this solution was explicitly ruled out for GC for C++ as the
problems were thought insoluble~\cite[p.~32]{boehm09garbage}. We break these
problems down into four:
(1) finalizers are prohibitively slower than destructors;
(2) finalizers can be run prematurely;
(3) running finalizers on the same thread as a paused mutator can cause race conditions and deadlocks;
(4) some safe destructors are not safe finalizers.

Fortunately for us, Rust's unusual static guarantees, suitably expanded by
\ourgc, allow us to address each problem in novel, satisfying, ways. In the following
section, we tackle these problems in the order above, noting that we tackle problems
\#1 and \#2 separately, and \#3 and \#4 together.


\section{Finalizer Elision}
\label{sec:elision}

Finalizers are much slower to run than destructors --- running every Rust destructor
as a GC finalizer in \ourgc causes a \somrselision{felide}{all}{percent} slowdown
in our benchmark suite. In this section we show how to sidestep much of this overhead.

A variety of factors contribute to the performance overhead of finalizers, such as:
a queue of finalizers
must be maintained, whereas destructors can be run immediately; since finalizers run
some time after the last access of a value, running them is more likely to involve
cache misses; and so on. Most of these factors are inherent to any GC and
our experience of using and working on \boehm -- a mature, widely used GC -- does
not suggest that it is missing optimisations which would reduce most of this overhead.

Instead, whenever possible, \ourgc \emph{elides} finalizers so that they do not need to be run at all.
We are able to do this because many Rust destructors
exclusively do work that a GC will do anyway --- when used as finalizers,
such destructors are unnecessary.

Consider the type \lstinline{Box<T>} which heap allocates space for a value;
when a \lstinline{Box<T>} value is dropped, the heap allocation will be freed
by \lstinline{Box}'s drop method. We can then make two observations. First,
\lstinline{Box<T>}'s drop method solely consists of a call to \lstinline{free}\footnote{The
function in the Rust API is actually called \lstinline{deallocate}, but that
jars with the terminology we use elsewhere.}. Second, while we informally say
that \lstinline{Box<T>} allocates on the `heap' and \lstinline{Gc<T>} allocates
on the `GC heap', all allocations are made through \boehm and stored in
a single heap. Thus, when used as a finalizer,
\lstinline{Box<T>}'s drop method is unneeded\footnote{There is a subtle asymmetry here: we
cannot elide the destructors themselves, as they are still necessary to ensure
predictable destruction in non-\lstinline{Gc<T>} Rust code.}, as the underlying memory will
naturally be freed by \boehm anyway. Indeed, since the drop method only
calls \lstinline{free}, any resulting finalizer would cause the underlying
allocation to live longer than if the finalizer was not present!

This means that there is no need to run a finalizer for a type such as
\lstinline{Gc<Box<u8>>} and we can statically elide it. However, we can not
elide every \lstinline{Gc<Box<T>>} finalizer: for example, \lstinline{Gc<Box<Arc<u8>>}
(where \lstinline{Arc<T>} is the thread-safe version of \lstinline{Rc<T>})
requires a finalizer because \lstinline{Arc<T>} needs to decrement a reference
count. This may seem confusing, because in both cases \lstinline{Box<T>}'s drop
method is the same: however, the drop glue added for \lstinline{Box<Arc<u8>>}
causes \lstinline{Arc<T>}'s destructor to be run.


\subsection{Implementing finalizer elision}

\begin{algorithm}[t]
\caption{Finalizer Elision}
\label{alg:elision}
\begin{algorithmic}
\Function{RequiresFinalizer}{$T$}
    \If {\Call{Impls}{$T$, $Drop$} \AND \NOT \Call{Impls}{$T$, $DropMethodFinalizerElidable$}}
        \State \Return{true}
    \EndIf
\ForEach {$field \in type$}
    \If{\Call{RequiresFinalizer}{$field$}}
        \State \Return{true}
    \EndIf
\EndFor
\State \Return{false}
\EndFunction
\end{algorithmic}
\end{algorithm}

\label{requires_finalizer_intrinsic}
The aim of finalizer elision is to statically determine which type's destructors do
not require corresponding finalizers and elide them. Our approach is conservative,
and deals correctly with drop glue.

The high-level \cref{alg:elision} says that any type which implements
the \lstinline{Drop} trait requires finalization unless it also implements the
new \lstinline{DropMethodFinalizerElidable} \emph{marker trait} (i.e.~a
trait without methods). This trait and can be
used by a programmer to signify that a type's drop method need
not be called if the type is placed inside a \lstinline{Gc<T>}. The `Drop'
part of the trait name is deliberate: it allows the programmer to reason
only about the `top-level' type. If the type has a transitively reachable field
has a type which implements the \lstinline{Drop} trait but not the
\lstinline{DropMethodFinalizerElidable} trait, then then the top-level type
still requires finalization. This not only checks drop glue, but allows the
programmer to safely reason about types with type parameters without knowing
the concrete types passed to those parameters.

Even though neither normal Rust destructors or \ourgc finalizers are guaranteed
to run, a program whose destructors or finalizers never run would probably not
be usable (e.g.~leaking resources such as memory, deadlocking, etc.). We
therefore make \lstinline{DropMethodFinalizerElidable} an unsafe
trait, because implementing it inappropriately is likely to lead undesired
(though not incorrect!) behaviour at run-time. To implement it one therefore
needs to opt in to unsafe Rust:

\begin{lstrustsmall}
unsafe impl<T> DropMethodFinalizerElidable for Box<T> {}
\end{lstrustsmall}

\ourgc modifies the standard Rust library to implement
\lstinline{DropMethodFinalizerElidable} on the following types: \lstinline{Box<T>},
\lstinline{Vec<T>}, \lstinline{RawVec<T>}, and \lstinline{HashMap<T>}. Fortunately,
not only are these types' drop methods compatible as-is with \lstinline{DropMethodFinalizerElidable},
but they are extensively used in real Rust code: as we shall see in \cref{sec:evaluation},
they are an important part of allowing us to elide significant numbers of finalizers in real code.

\begin{figure}[t]
  \begin{lstlisting}[language=Rust, numbers=none, basicstyle=\footnotesize\ttfamily,
    label={listing:elision_in_rustc}, caption={
      A simplified view of how finalizers are elided inside \ourgc. The new compiler intrinsic
      \lstinline{requires_finalizer} returns true if a finalizer is required for a
      type. The \lstinline{Gc<T>} type uses this intrinsic to ensure that the
      value is registered as requiring a finalizer. Because \lstinline{requires_finalizer}
      is a \lstinline{const} function, with optimisations turned on, it is inlined
      and the branch optimised away. In other words, the seemingly dynamic, branching code
      in \lstinline{Gc::new} turns into static, branchless code.
    }]
impl<T> Gc<T> {
  pub fn new(value: T) -> Self {
    if requires_finalizer::<T>() { Gc<T>::new_with_finalizer(value) }
    else { Gc<T>::new_without_finalizer(value) }
    ...
  }
}
\end{lstlisting}
\end{figure}

\cref{listing:elision_in_rustc} shows how we use the \lstinline{const} compiler intrinsinc
\lstinline{requires_finalizer} to turn \cref{alg:elision} into reality in our
\rustc fork. \lstinline{Gc::new} uses this intrinsic to decide
whether a finalizer must be registered or not. Although this looks like
a dynamic check, in fully optimised builds it turns into a static
check: \lstinline{requires_finalizer} is
evaluated at compile-time and its result can be inlined into \lstinline{Gc::new};
this then allows the associated conditional to be removed too. In other words --
compiler optimisations allowing -- the `does this specific type require a
finalizer?' checks have no run-time cost at all.


\section{Premature Finalizer Prevention}
\label{sec:premature_finalize_prevention}

\begin{figure}[tb]
\begin{lstlisting}[
  language=Rust, basicstyle=\footnotesize\ttfamily,
  caption={An example of code that, when fully optimised, can cause premature
    finalization. We create a new struct \lstinline{S} that wraps an integer
    (line 1) with a drop method that sets the integer to zero (line 2). In the
    main method, we first move an instance of the struct into a
    \lstinline{Box<T>}, then move that into a \lstinline{Gc<T>} (line 4). We
    then obtain a Rust reference to the inner integer (line 5), which at
    run-time will be a pointer to the \lstinline{Box<T>} on the heap. At this
    point, the compiler can realise that the \lstinline{Gc<T>} is no longer
    used and overwrite \lstinline{root}'s pointer (which may be in a register). If
    a GC cycle then occurs, a finalizer might run \lstinline{S}'s drop method;
    the program will then print `0' instead of the expected `1' (line 7).},
    label={fig:premature_finalization}]
struct S { value: u8 }
impl Drop for S { fn drop(&mut self) { self.value = 0; } }
fn main()  {
  let root = Gc::new(Box::new(S{ value: 1 }));
  let inner: &u8 = &**root.value;
  force_gc();
  println!("{}", *inner);
}
\end{lstlisting}
\end{figure}

Most of us assume that finalizers are always run after the
equivalent destructor would have run, but they can sometimes run
prematurely~\cite[section~3.4]{boehm03destructors}.
As described thus far, premature finalization is also possible in \ourgc
(see~\cref{fig:premature_finalization}). In this section we
show how we can turn a seemingly inefficient
approach to premature finalization prevention into a viable solution.

There are two aspects to premature finalization. First, language
specifications often do not define, or do not precisely define, when the earliest point that a value can
be finalized is. While this means that, formally, there is no `premature' finalization,
it seems unlikely that language designers anticipated some of the resulting
implementation surprises (see e.g.~this example in
Java~\cite{shipilev20local}). Second most compiler optimisations are
`GC unaware', so optimisations such as scalar
replacement can change the point in a program when GCed values appear to be
finalizable.

In our context, it is trivial to define premature finalization as a (dynamic) finalizer
for a \lstinline{Gc<T>} value running before the (static) \lstinline{Gc<T>} owner
has gone out of scope. Similar to the high-level proposal mooted
in~\cite[Solution~1]{boehm07optimization}, we must therefore ensure that the dynamic
lifetime of a GC pointer matches, or exceeds, the static lifetime of the
\lstinline{Gc<T>} owner.

Our solution relies on using \lstinline{Gc<T>}'s drop method to \emph{keep
alive} GCed value for the static lifetime of the \lstinline{Gc<T>} itself. In
other words, we ensure that the conservative GC cannot observe the GCed value
being unused until all of its normal Rust owners of type \lstinline{Gc<T>} have
gone out of scope.

However, there is one major problem to overcome: copyable types such as
\lstinline{Gc<T>} are forbidden from having destructors. The fundamental
challenge we have to solve is that each copied value will have a destructor
called on it, which has the potential for an underlying value to be destructed
more than once. \ourgc explicitly allows \lstinline{Gc<T>} -- but no other
copyable type -- to have a destructor, but to ensure it doesn't cause surprises
in the face of arbitrary numbers of copies, the destructor must be idempotent.
Our task is made easier because \lstinline{Gc<T>} has no drop glue: Rust does
not add a destructor for pointer types, and from the perspective of the type
system \lstinline{Gc<T>} is simply a wrapper around a pointer type.

We therefore only need to make sure that \lstinline{Gc<T>}'s drop method
is idempotent. Fortunately, this is sufficient for our purposes: we want the drop
method to inhibit finalization but that does not require run-time side effects.
We therefore use a memory fence in the form of a keep-alive
function. Simplifying somewhat, memory fences can be thought of as having both
compile-time and run-time effects:
they prevent compilers from reordering computations around a given address;
and the manner in which this is done also also ensures that CPUs
cannot reorder computations relevant to that address.
Keep-alive functions are highly platform (compiler, operating
system, and CPU) specific: we use \boehm's \lstinline{GC_reachable_here}
function\footnote{This is actually a macro, and our fork of \boehm provides a
function \lstinline{GC_keep_alive} to expose the macro to Rust.}
which abstracts over these details. \lstinline{Gc<T>}'s
implementation of the \lstinline{Drop} trait therefore looks as follows:

\begin{lstlisting}[language=Rust, basicstyle=\footnotesize\ttfamily]
impl<T: ?Sized> Drop for Gc<T> {
   fn drop(&mut self) { unsafe { bdwgc::GC_keep_alive(self as *mut u8) }; }
}
\end{lstlisting}


\subsection{Optimising premature finalizer prevention}

The drop method we add to \lstinline{Gc<T>} fully prevents premature
finalization. It also naturally solves a performance problem with the suggested solution
for C++ in~\cite[Solution~1]{boehm07optimization}, which requires keeping alive
all pointers, no matter their type, for their full scope. By definition, our
solution only keeps alive \lstinline{Gc<T>} values: the compiler is free to
optimise values of other types as it so wishes. However, our approach still
imposes a performance overhead on code that uses
\lstinline{Gc<T>}: in the worst case in our benchmark suite, the overhead is
\somrsbarriers{bnaive}{fibonacci}{speedup} \laurie{this figure seems wrong}.

Fortunately, we can optimise premature finalizer prevention further by
piggy-backing on finalizer elision: if a finalizer can be
elided, there is no finalizer to be called prematurely, and no need for
resulting values to be kept alive. Intuitively, we want to avoid generating drop methods
for \lstinline{Gc<T>} types that do not require finalization,
but this is difficult to do directly inside \rustc. Instead,
we suppress calls to the drop methods of such types: the two approaches
are functionally equivalent, though ours
does put an extra burden on dead-code elimination in the compiler tool-chain.

We add a new pass
\lstinline{remove_elidable_drops} to
\rustc's Mid-Level Intermediate Representation (MIR) processing. MIR is best
thought of as the main IR inside \rustc: it contains the complete set of
functions in the program, where each function consists of a sequence of basic
blocks. Simplifying somewhat, function and drop method calls are represented as
different kinds of \emph{terminators} on basic blocks. Terminators
reference both a callee and a successor basic block.

The \lstinline{remove_elidable_drops} pass iterates over a program's MIR,
identifies drop method terminators which reference elidable finalizers (using
the \lstinline{requires_finalizer} intrinsic from
\cref{requires_finalizer_intrinsic}), and turns them into `goto' terminators
to the successor basic basic block. \cref{alg:barrier_removal} in the appendix
gives a more formal version of this algorithm.


\section{Finalizer Safety Analysis}
\label{sec:fsa}

In this section we address two high-level problems: running finalizers on the same thread
as a paused mutator can cause race conditions and deadlocks; and some safe destructors are not
safe finalizers. Addressing the former problem is conceptually simple --
finalizers must be run on a separate thread -- but we must ensure that doing so
is sound. We therefore consider this a specific instance of the latter problem,
treating all equally in this section.

In this section we introduce the three main factors that constitute
Finalizer Safety Analysis (FSA).
We extend Rust's static analyses, and alter the relevant parts
of \rustc, to reject a type \lstinline{T}'s destructor if it
is not provably safe to be used as a finalizer in a \lstinline{Gc<T>}.


\subsection{Rust references}
\label{sec:fsa_rust_references}

\lstinline{Gc<T>} can store, directly or indirectly, normal Rust
references (i.e.~\lstinline{&} and \lstinline{&mut}), at which point it is
subject to Rust's normal borrow checker rules and cannot outlive the reference.
However, finalizers can dynamically extend the lifetime of a GCed value,
including any stored reference: if a finalizer accesses a reference stored in a
\lstinline{Gc<T>} it implicitly undermines Rust's borrow checking rules.

The simplest way of avoiding this problem would be to forbid \lstinline{Gc<T>}
from storing, directly or indirectly, references. This might seem to be
no great loss: storing references in a \lstinline{Gc<T>} largely nullifies
the `GCness' of \lstinline{Gc<T>}. We have found, however, that when refactoring
or experimenting with existing code, it is useful to be able to store references
in \lstinline{Gc<T>}. FSA therefore enforces a more relaxed rule: a \lstinline{Gc<T>} can only store,
directly or indirectly, references if it has no finalizer (i.e.~\lstinline{T}
has no destructor, or finalizer elision has removed the \lstinline{Gc<T>}'s
finalizer).

To implement this aspect of FSA, \ourgc uses auto traits~\cite[Section.~11]{rustlangref},
which can be thought of as marker traits that the compiler recognises and
handles in a special way. Since we use auto traits repeatedly in FSA,
it is worth understanding how they work. In essence, an auto trait \lstinline{A}
will be automatically implemented for a type \lstinline{T} unless
one of the following is true: there is an explicit \emph{negative
implementation} of \lstinline{A} for \texttt{T}; or \texttt{T}
contains a field that is not itself \lstinline{A}. Informally, we
say that a negative implementation of an auto-trait \emph{pollutes} containing
types.

We therefore introduce a new auto trait \lstinline{ReferenceFree}, which
denotes a type which does not contain a reference. Crucially, \ourgc defines
two negative (`\lstinline{!}') implementations of \lstinline{ReferenceFree} for
reference types:

\begin{lstlisting}[language=Rust, basicstyle=\footnotesize\ttfamily]
impl<T> !ReferenceFree for &T {}
impl<T> !ReferenceFree for &mut T {}
\end{lstlisting}

Thus, thanks to auto traits, any type \lstinline{T} which implements
\lstinline{ReferenceFree} is guaranteed to be free of references. When a
program contains a \lstinline{Gc<T>} type, \ourgc checks whether it has a
finalizer: if it does,
and \lstinline{T} does not implement \lstinline{ReferenceFree}, an error is
raised.


\subsection{Cycles and Finalization}
\label{sec:cycles_and_finalization}

\begin{figure}[tb]
\lstinputlisting[language=Rust, basicstyle=\footnotesize\ttfamily,
  firstline=5]{listings/finalization_cycle.rs}
\captionof{lstlisting}{An example of the problems that come from mixing cycles
  and finalization. The salient difference from~\cref{fig:first_example} is that
  the drop method sets the value of a field inside \lstinline{nbr}. Running this
  program on a strong memory model machine would non-deterministically print \lstinline{2 0} or \lstinline{1 0}
  depending on whether \lstinline{gc1} or \lstinline{gc2} is finalized first.
  The `seemingly expected' output of \lstinline{1 2} or \lstinline{2 1} would
  never be printed: whichever GCed value is finalized first changes what the
  other GCed value sees in its finalizer. As that implies, this example is
  unsound: the second finalizer to run leads to undefined behaviour.}
\label{fig:finalizer_cycle}
\end{figure}

One of the main motivations for GCs is that they solve problems with cyclic
data structures. However, finalizers can be unsound if they access
state shared within members of a cycle. \cref{fig:finalizer_cycle} shows an example of undefined
behaviour when two GCed values create a cycle and both their
finalizers reference the other GCed value. Whichever order the finalizers are
run in, at least one of the finalizers will see the other GCed value as partly
or wholly `finalized'.

Most languages and systems we are aware of assume that users either don't run into
this problem (finalization cycles are considered rare in GCed
languages~\citep[p.~229]{jones16garbage}) or know how to deal
with it when they do (e.g.~refactoring the types into parts that do and don't
require finalization~\cite[p.~11]{boehm03destructors}). There is no fully
automatic solution to this problem, with the closest solution being those GCs
which offer weak references, allowing users to detect when finalization cycles
have been broken, though they still have to deal with the consequences
manually.

In \ourgc, we wanted to ensure that users cannot accidentally find themselves
making such a mistake. A first attempt at enforcing such a property might
seem to be that a \lstinline{Gc<T>} cannot have, directly or indirectly, fields of type
\lstinline{Gc<T>}. This would indeed prevent the mistakes we want to catch but
at the cost of not allowing \lstinline{Gc<T>} with a finalizer to specify shared ownership!

Our approach is therefore very different to normal Rust type checks: instead of
checking an entire type, we check only that the type's destructor does not,
directly or indirectly, access a \lstinline{Gc<T>}. This is implicitly a non-strict
subset of the normal type check, allowing GCed types to express cycles so long
as their destructor(s) do not access other GC types.

To make this check easier to implement, we introduce
another auto trait \lstinline{FinalizerSafe}, with a negative implementation on
\lstinline{Gc<T>}:

\begin{lstrustsmall}
impl<T> !FinalizerSafe for Gc<T> {}
\end{lstrustsmall}

This naturally handles transitively reachable code, allowing FSA itself to only
check that a destructor's direct field accesses are \lstinline{FinalizerSafe}.


\subsection{Destructors need to be runnable on the finalizer thread}
\label{sec:fsa_finalizer_thread}

\begin{figure}[t]
\lstinputlisting[language=Rust, basicstyle=\footnotesize\ttfamily,
 firstline=10]{listings/finalizer_deadlock.rs}
\captionof{lstlisting}{How destructors can cause deadlocks when used as
  finalizers. The mutator creates a reference-counted mutex (line 6),
  placing a copy in a \lstinline{GcNode} that immediately goes out of scope
  (line 7). The mutator then acquires the lock (line 8) but before it
  can release the lock a GC cycle occurs and the \lstinline{GcNode}'s
  finalizer run (line 9). If the finalizer is run on the same thread
  as the mutator, then it will fail to grab the lock (line 2) and cause
  a deadlock as the mutator cannot continue and release the lock.}
\label{fig:finalizer_deadlock}
\end{figure}

Virtually all destructors access state, whether that is in the GCed value they are
attached to, or global state. When used as finalizers, accessing such state can
be problematic, turning sound destructors into unsound finalizers. For
example, acquiring a lock can cause deadlocks if the mutator has already
acquired that lock and the finalizer is run on the same thread as the
mutator~\cite[Section~3.3]{boehm03destructors}. Locks are not the only problem:
data races of other kinds are also possible when destructors are run as
finalizers and can interleave with mutator code~\cite{niko13destructors}.

The solution to these problems is to ensure that finalizers are never
interleaved with mutator code on the same thread. The most general, and
practical, way to achieve this is to run finalizers on a thread(s) that never
runs mutator code. While such a thread(s) could perform other non-mutator work,
it is simplest to think of a thread dedicated solely to running finalizers and
hence we refer to it as the \emph{finalizer thread}.

We must therefore ensure that it is safe to run a type's destructor on the
finalizer thread. A conservative definition is that \lstinline{Gc<T>} is
is safe to use if \lstinline{T} implements both of Rust's existing \lstinline{Send} (is a type safe to be
moved permanently from one thread to another?) and \lstinline{Sync} (is a type
safe to be accessed from more than one thread?) auto traits.
Note that it is not sufficient for \lstinline{T} to implement
\lstinline{Send} alone, because a finalizer may access
state (e.g.~stored in an \lstinline{Arc}) shared between a GCed value and
non-GCed value. If the finalizer runs while the non-GCed value is still in
scope, the mutator and finalizer threads may access
the underlying value simultaneously.


\subsubsection{Relaxing the \lstinline{Send + Sync} restriction}

Requiring that finalization is only possible for types that implement both \lstinline{Send} and
\lstinline{Sync} can occasionally be frustrating, in part because more types
implement \lstinline{Send} than \lstinline{Sync}. Experimentally, FSA
does not check that the top-level types implement \lstinline{Send} than \lstinline{Sync},
instead extending the destructor-checking approach of
\cref{sec:fsa_finalizer_thread}: destructors
may only access fields that implement both \lstinline{Send} and
\lstinline{Sync}.

This relaxed check is undoubtedly more dangerous than that of
\cref{sec:fsa_finalizer_thread}, which is why we mark it as experimental. We
believe that it is compatible with Rust's semantics (at least at the time of
writing), and our examination of the compiler tool-chain
(i.e.~\rustc and LLVM) showed that it does not implement the analyses and
optimisations that could undermined our check. However, there are
other languages and implementations where our check would not be valid
(for example our assumption would be unsafe
in Java due to synchronisation removal~\cite{wang06escape}). We leave as an
open question to others as to whether Rust should deliberately permit or forbid
such checks in its semantics.

\laurie{in our benchmark suite, how often does this relaxation make a difference?}\jake{I will post a write-up here once I have the numbers from all the benchmarks}


\subsection{Bypassing FSA checks when necessary}

FSA is deliberately conservative. In particular, when checking whether drop
methods satisfy certain properties, FSA naturally checks whether code
reachable from those drop methods satisfies those properties. Currently,
function calls which are inlined are checked in detail, but all other function
calls are assumed it fails to meet the stated
property. Calls to non-lined normal Rust functions are not checked due to
a minor limitation inside \ourgc. Other kinds of function call are fundamentally
hard or impossible to check, specifically: calls to externally linked (e.g.~an FFI
call to C) function; or dynamic dispatch calls in \emph{trait objects}, where we can't
tell which of many possible implementations of a method will actually be
called.

In some cases, users are able to prove to their satisfaction that the resulting
false positives are unnecessary (e.g.~because the C function they are calling
has no side effects). Depending on the error they receive, they can then
implement the unsafe traits \lstinline{FinalizerSafe}, \lstinline{Send}, or
\lstinline{Sync} appropriately. A challenge in all three cases is that
implementing a trait implicitly guarantees that all dynamic values
satisfy the static trait implementation.

One way to sidestep this problem is to provide a newtype that allows only a
subset of values to be declared as safe to use in a finalizer: the newtype
implements the \lstinline{FinalizerSafe}, \lstinline{Send}, and \lstinline{Sync}
traits, implicitly blessing the type it wraps. We found a particular need for
this when interfacing with external GC-unaware libraries. \ourgc thus provides
a standard newtype \lstinline{FinalizerUnchecked<T>} which allows allows users to inform
FSA that certain uses of
a type \lstinline{T} satisfy its properties. We still want to require the user
to explicitly opt-in to unsafe Rust when using
\lstinline{FinalizerUnchecked<T>}, since incorrect use is dangerous,
but Rust structs cannot be marked as unsafe directly. Instead we mark
the struct's constructor (\lstinline{FinalizerUnchecked::new}) as
unsafe.


\subsection{Putting it all together}

\begin{algorithm}[t]
  \captionof{algorithm}{Finalizer safety analysis}
  \label{alg:fsa}
  \begin{algorithmic}[1]
    \Function{FinalizerSafetyAnalysis}{\textit{func}}
      \ForEach {\textit{basic\_block} $\in$ \textit{func}}
            \State $t \gets$ \textit{basic\_block.terminator}
            \If {\NOT \Call{IsGcConstructorCall}{$t$}}
                \State \textbf{continue}
            \EndIf
            \State \textit{ty} $\gets$ \Call{GetTyOfGcValue}{$t$}
            \If {\Call{isFinalizerUnchecked}{\textit{ty}} \OR \NOT \Call{RequiresFinalizer}{\textit{ty}}}
              \State \textbf{continue}
            \EndIf
            \If { \NOT \Call{ImplementsTrait}{\textit{ty}, \textit{ReferenceFree}}}
            \State \Call{EmitReferenceError}{}
            \Else
            \ForEach {$drop\_method \in$ \Call{GetDropGlue}{\textit{ty}}}
              \If { \NOT \Call{IsMIRAvailable}{\textit{drop\_method}}}
                  \State \Call{EmitFinalizerUnsafeError}{}
              \EndIf
              \State \Call{CheckDropMethodSafety}{\textit{drop\_method}}
            \EndFor
            \EndIf
      \EndFor
\EndFunction
\State{}
    \Function{CheckDropMethodSafety}{\textit{drop}}
    \State $ty \gets$ \Call{GetTyOfDropValue}{\textit{drop}}
    \If {\Call{IsFinalizerSafe}{\textit{ty}}}
      \State \Return
    \EndIf
      \ForEach {\textit{basic\_block} $\in$ \textit{drop}}
        \ForEach {$\textit{statement} \in \textit{basic\_block}$}
            \ForEach {$\textit{projection} \in \textit{statement}$}
              \If{\NOT \Call{IsFinalizerSafe}{\textit{projection.element}}}
                  \State \Call{EmitFinalizerUnsafeError}{}
              \EndIf
            \EndFor
        \EndFor
      \EndFor

\EndFunction
\State{}
  \Function{IsFinalizerSafe}{\textit{ty}}
    \State \Return{\Call{Impls}{\textit{ty}, $Send$} \AND {\Call{Impls}{\textit{ty}, \textit{Sync}}} \AND {\Call{Impls}{\textit{ty}, \textit{FinalizerSafe}}}}
\EndFunction
\end{algorithmic}
\end{algorithm}

\cref{alg:fsa} puts all the parts of FSA together. In essence, it iterates over
every function in \rustc's MIR and checks whether types used in a
\lstinline{Gc<T>} satisfy FSA. As the algorithm shows, the seemingly
separate parts of FSA are able to use much of the same machinery (and reuse
algorithms from earlier sections).

To simplify the presentation, the algorithm as presented performs no caching,
so a type can be checked multiple times. The actual implementation of the
implementation inside \ourgc performs caching. For example, the
\lstinline{requires_finalizer} intrinsic caches results, and the MIR transform
API naturally caches several other calculations as well.

The \lstinline{Emit*Error} functions represent an important convenience. Rather
than just inform a user that `your drop method has not passed FSA', \ourgc
pinpoints precisely which field or line in a drop method caused FSA to fail.
\lstinline{EmitReferenceError} informs the user when a reference in a type
is used in a way that violates FSA (see~\cref{sec:fsa_rust_references}).
\lstinline{EmitFinalizerUnsafeError} informs the user when a drop method
contains code which is unsafe (e.g.~references a \lstinline{Gc<T>} type, an
opaque function, etc.).

\begin{figure}[tb]

\lstinputlisting[language={}, basicstyle=\footnotesize\ttfamily, numbers=none]{listings/finalization_cycle.stderr}
           \captionof{lstlisting}{The compiler error produced by FSA for the example in \cref{fig:finalizer_cycle.}}
\label{fig:finalizer_cycle_err}
\end{figure}

\section{Performance Evaluation}
\label{sec:evaluation}

\begin{table}[t]
\begin{center}
\begin{tabular}{lll}
\toprule
  Benchmark & Version & Description \\
\midrule
  \binarytrees & Debian CLBG \binarytreesversion  & Heap allocation microbenchmark \\
  \grmtools & \grmtoolsversion  & Lexer / parser library \\
  \minimoka & \minimokaversion  & Concurrent cache library \\
  \regexredux & Debian CLBG \regexreduxversion  & Regular expression matching \\
  \sws & \swsversion  & Web server\\
  \midrule
  \somrsast & git \#\somrsversion  & SOM AST VM\\
  \somrsbc & git \#\somrsversion  & SOM bytecode VM\\
  \yksom & git \#\yksomversion  & SOM bytecode VM\\
\bottomrule
\end{tabular}
\end{center}

  \vspace{5pt}
  \caption{Our suite of benchmarks: we take these Rust programs and alter them
  to use different memory allocation strategies (\ourgc, \lstinline{Rc<T>},
  etc.). The top half of the table shows a traditional suite of benchmarks. The
  bottom half shows three SOM (a programming language) VMs. For all three SOM
  VMs, we use the same SOM version of the `Are We Fast Yet?' benchmark suite
  (git\#\awfyversion)\cite{marr16cross}; each SOM VM is thus a proxy for 26 additional benchmarks.}
\label{tab:benchmarks}
\end{table}

To understand the performance of \ourgc, and the various aspects that make it
up, we carried out several performance experiments. In this section we explain
our methodology and our experimental results.


\subsection{Methodology}

We ran four main experiments:

\vspace{6pt}
\begin{tabular}{ll}
  \Egcrc & the relative performance of \texttt{Gc<T>} over other allocation strategies (e.g.~\texttt{Rc<T>}) \\
  \Eelision & the performance gains of finalizer elision \\
  \Eprem & the costs of premature finalizer prevention \\
  \Epremopt & the performance gains from optimising premature finalizer prevention
\end{tabular}
\vspace{10pt}

There is no existing benchmark suite for GCs for Rust. Even if such a suite did exist, it
may not have been suitable for our experiment because in experiment \Egcrc we
want to compare programs using existing shared ownership approaches such as \lstinline{Rc<T>} against
\lstinline{Gc<T>}. We searched through tens of the most popular
Rust libraries on \lstinline{crates.io} (the \emph{de facto} standard Rust
package system) looking for suitable candidates. Many that use
shared ownership strategies do not use them in performance
critical areas (\laurie{give two examples}): any resulting benchmark would be
unlikely to show anything of interest to this paper . Some relied on
unusual and/or unsafe features of their memory strategy that were too difficult
or time-consuming to adapt (e.g.~\emph{RustPython}, \emph{Rkyv}).

\cref{tab:benchmarks} shows our eventual benchmark suite, including programs
using the following shared ownership strategies: \lstinline{Arc<T>}, \lstinline{Rc<T>}, \rustgc (an existing GC for
Rust), and \typedarena (an arena library). \binarytrees and \regexredux
are well-known microbenchmarks. \binarytrees is both allocation intensive
and sufficiently simple that we could port it to a variety of shared ownership strategies.
The remaining benchmarks are `real' libraries and programs that we
ported from their existing shared ownership strategy to \lstinline{Gc<T>}: \grmtools is a
parsing library which uses \lstinline{Rc<T>} extensively; \minimoka
\laurie{uses what?}; \sws is built on top of the \emph{Hyper} HTTP library,
which itself uses the \emph{tokio} async runtime and uses \lstinline{Arc<T>}
extensively.

Our suite also includes three SOM VMs. SOM is a small, but complete,
Smalltalk-esque language with a wide variety of implementations. \somrsast and
\somrsbc are existing implementations, both relatively faithful ports of a Java
SOM VMs into Rust that use \lstinline{Rc<T>}. \yksom is a from-scratch rewrite
for this paper that is designed to be more idiomatic and higher performance.
Crucially, the SOM VMs enable us to run the same `Are We Fast Yet?'
benchmark suite~\cite{marr16cross}, turning what appears to be 1 benchmark into 26
(mostly micro) benchmarks.

One confounding factor we have controlled for is the underlying memory
allocator. \boehm's core dates to the 1980s and allocators have made
many advances since. A quick experiment showed us that modern system
allocators are much faster than \boehm: comparing \ourgc with \boehm
to \rustc with a modern system allocator would be uncomfortably
close to apples and oranges. We therefore use \boehm as the allocator
for both \ourgc and \rustc.

We ran each benchmark in our suite 30 times reporting 99\% confidence intervals
\laurie{what about the memory benchmarks --- those don't have CIs?}. For those
benchmarks reporting timings, we measured wall-clock time of a process using
the standard Unix \lstinline{time} command. \laurie{how did we measure memory?}

\jake{\binarytrees, \regexredux and the SOM VMs all use rebench\cite{rebench18marr}}
\laurie{why don't we use \lstinline{time} for binarytrees and regexredux?}


\subsection{Results}

\begin{table}[t]
\scalebox{0.7}{%
  \input{table_overview}
}
  \vspace{5pt} \caption{Overview of results across all benchmarks. \jake{TODO:
  mini-moka}. For \binarytrees, typed-arena performs the best, however, it
  allocates the most amount of memory (\jake{percent more than \ourgc}) because
  it removes it all in one go at the end. \rustgc performs the worst and
  looking at the perf report this is because most of the time is spent in its
  cycle-tracing code (which is not very well optimised at all). \grmtools is an
  allocation heavy benchmark, and while \rc is \jake{percent} faster over the
  entire suite of Java programs, it uses far more memory than \ourgc
  (\jake{percent}on average). (see \cref{fig:grmtools} in the Appendix for a
  breakdown of this over the individual Java projects). \sws is a production
  static http server which we converted to use \ourgc in it and its
  \emph{hyper} request library. We use the standard \emph{wrk} http
  benchmarking tool to fire as many requests as possible to \sws in one minute.
  This benchmark measures the number of http requests per second which
  \emph{wrk} received responses to and shows the number of requests per second.
  For the SOM VMs, we report the geometric mean across all 26 benchmarks. We
  are unable to report a comparison for \yksom as it was infeasible to port
  this to use \rc (or another shared memory strategy). Note the stark
  performance differences between \ourgc and \rc for \somrsast. This is because
  (unlike for \somrsbc) we are only able to elide \jake{perc elided}
  finalisers, (compared to \somrsbc's \jake{input}). Each benchmark is run for
  30 process executions, and we report 99\% confidence intervals.}
  \label{table:overview}
\end{table}

\autoref{table:overview} shows the results for this experiment. The results
shows that for \binarytrees (an allocation heavy benchmark)
\textsc{Typed-arena} was the fastest as it never performs any deallocation
during the benchmark run, it simply deallocates all memory at the end.

\rustgc performs poorly for two reasons. First, it uses a form of reference
counting to track the roots for each garbage collected object. Second, it has a
naive implementation of the mark-sweep algorithm and does not use parallel
collector threads.

% \begin{figure}[t!]
%     \centering
%     \includegraphics[width=1\textwidth]{plots/som_rs_perf.pdf}
%     \caption{Results from the \somrs micro-benchmark experiment, where the SOM
%     benchmark suite is run to compare two configurations of \somrs: \somrsrcbdwgc, where SOM objects are managed with RC but use the BDWGC's allocator with GC disabled; and \somrsgc, where SOM objects are managed using \ourgc's GC library, which uses the BDWGC's allocator. Each benchmark is run for 100 process
%     executions, where the error bars represent 99\% confidence intervals.}
% \label{graph:som_rs_finalizers}
% \end{figure}

\begin{figure}[t!]
    \centering
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=1\textwidth]{plots/elision.pdf}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{plots/elision_mem.pdf}
    \end{subfigure}
    \caption{Performance (left) and memory (right) results of the \Eelision
    experiment. For all three SOM VMs, we use the same SOM version of the `Are
    We Fast Yet?' benchmark suite and take the geometric mean of all 26
    benchmarks. \emph{Elision} shows the results after \ourgc's finalizer
    elision optimisation (\cref{sec:elision}) and \emph{Naive} is with no
    optimisation applied. Each benchmark is run for 30 process executions,
    where the error bars represent 99\% confidence intervals.}
\label{fig:elision}
\end{figure}

\begin{figure}[t!]
    \centering
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{plots/barriers.pdf}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[width=\textwidth]{plots/barriers_mem.pdf}
    \end{subfigure}
    \caption{Performance (left) and memory (right) results of the \Epremopt
    experiment. For all three SOM VMs, we use the same SOM version of the `Are
    We Fast Yet?' benchmark suite and take the geometric mean of all 26
    benchmarks. \emph{None} shows the results where there are no compiler
    barriers (which is unsound); \emph{All}, where every single \lstinline{Gc}
    reference has a corresponding barrier; and \emph{None}, where barriers can
    be optimised away where \ourgc is certain they are unnecessary. Each
    benchmark is run for 30 process executions, where the error bars represent
    99\% confidence intervals. We have disabled finaliser elision for this experiment. \jake{It's difficult to draw conclusions about this
    because of a) overlapping CIs b) the non-determinism in how barriers affect the optimiser and
    when GCs are scheduled c) how long things will be kept alive for
    finalisation} \jake{show the difference in finalisable objects run} A more detailed breakdown is available in Appendix \cref{fig:barriers_breakdown}}
\label{fig:barriers}
\end{figure}


\section{Threats to validity}

We cannot state with certainty that the solutions we have presented are
complete or correct. We have tried to mitigate this by relatively extensive
testing. We have created a number of new tests inside our \rustc fork
\laurie{how many?}. We also ported a number of existing programs to \ourgc --
including programs that we did not expect to make good benchmarks -- since some
GC problems only manifest at scale. However, we could undoubtedly have performed wider
testing, investigated fuzzing, and so on: it is inevitable that there will be
bugs in \ourgc that are entirely our fault. Some of these bugs might have
coloured our performance results.

Our definition of the problems, the design of our solutions, and the way we
implemented them are presented in a fairly informal manner. Though we must
admit that this partly reflects our backgrounds, a truly formal definition
would be challenging for two reasons. First, at the time of
writing, Rust's semantics remain imprecise and incomplete, though this
situation is gradually improving. Second, the problematic
aspects of GC we tackle in this paper have resulted from careful analysis of
running systems (e.g.~\cite{boehm03destructors}): to the best of our knowledge,
no formalism of GC exists which fully covers these aspects. We suspect this is
a mixture of: a lack of research on this problem; the challenging
temporal aspects of GC; and, possibly, a poor fit with existing formalisms.
The closest analogue we know of is the evolving research literature on memory
models which, in a sense, modern GC is a superset of.

Any performance judgements we make are necessarily contingent on our particular
benchmark suite. We cannot say, for example, that finalizer elision will always
improve performance by the \laurie{X\%} we see in our experiment: there
undoubtedly exist reasonable, non-pathological, programs which will see
performance changes beyond those our results suggest. Although the \Egcrc
experiment requires a very specific benchmark suite, our other experiments
would probably be a good fit for a standard benchmarking suite.
Since the benchmark suite in this paper is the largest for any GC in Rust \laurie{is that true of
Bronze?}, it may serve as a partial basis for such a suite in the future.

Using \boehm as the allocator for all benchmarks has the advantage of removing
`pure' allocator performance as a confounding factor, but does mean that some
of the performance characteristics of benchmarks will be changed (e.g.~the
impact on CPU caches). A generic, modern conservative GC, using the insights of
recent non-GC allocators, would probably give a better idea of the true
performance of \ourgc relative to other shared ownership strategies.
Unfortunately, we are not aware of work on a modern, generic conservative GC.
Based on the work that modern allocators require, we suspect it would take
several person years to develop a truly competitive generic, modern
conservative GC.


\section{Related work}
\label{sec:related_work}

In this paper we have, we hope, given sufficient background on GC and the use
of destructors and finalizers in general. In this section we first survey the major
parts of the GC for Rust landscape more widely, though our survey is
necessarily incomplete, in part because this is a rapidly evolving field, before
briefly mentioning some non-Rust GC work that may give useful pointers.


\subsection{GCs for Rust}

Early versions of Rust had managed pointers (using the \lstinline{@T} syntax)
which were intended to model `full' GC, though whose implementation did not
progress beyond reference counting. This support was removed\footnote{In commit
\url{https://github.com/rust-lang/rust/commit/ade807c6dcf6dc4454732c5e914ca06ebb429773}.}
around a year before the first stable release of Rust. This was not the end
of the story for `GC as a core part of Rust', with core Rust developers exploring
the problem space in more detail~\citep{felix15specifying, felix16roots,
manish16gc}. However, efforts in this direction seem to have petered out,\jake{Though manishearth did a survey in 2021 \cite{manish21arena}}
at which point those interested in GC for Rust largely moved from anticipating
\rustc support to expecting to have to do everything in user-level libraries.

One of the earliest user-level GC for Rust libraries is
\textsc{BaconRajanGC}~\citep{rustbacon}, an implementation of the well-known GC
algorithm~\citep{bacon01concurrent}. This provides a type \lstinline{Cc<T>}
which is similar in intention to \ourgc's \lstinline{Gc<T>}, though using
reference counting and manually invoked cycle detection via the
\lstinline{collect_cycles} function. In order for this function to correctly
trace fields, users must manually implement a \texttt{Trace} trait which
traverses a type's fields. Destructors
are used as finalizers: to avoid the problems with Rust references we solved in
\cref{sec:fsa_rust_references}, \textsc{BaconRajanGC} imposes a \lstinline{T: Static}
bound on the type parameter passed to \lstinline{Cc<T>}. This is more restrictive
than \ourgc's \lstinline{Gc<T>}. However, unlike our approach in
\cref{sec:cycles_and_finalization}, it does not prevent finalizers accessing
shared data, and so seemingly safe destructors can undermined soundness (see
\laurie{let's put an example in the appendix}\jake{It will panic at runtime. I'm not sure if this is technically a soundness problem, because you can't do memory unsafety.}). Unlike most other GCs for
Rust, destruction in \textsc{BaconRajanGC} can be
seen as deterministic: GCed values outside cycles have their destructors run as soon as their reference count is
0; GCed values inside cycles at the end of the \lstinline{collect_cycles} function.

Probably the best known GC for Rust is \rustgc~\cite{manish15rustgc} (partly
covered in \cref{sec:destructor challenges}). \rustgc provides an API closer to
\ourgc's \lstinline{Gc<T>}, with the notable exception that its \lstinline{Gc}
is not, and indeed cannot be, copyable, thus always requiring calls to
\lstinline{Gc::clone} \laurie{does it have into\_raw?}\jake{no}. Similarly to
\textsc{BaconRajanGC}, GCed values are reference counted, with occasional
tracing sweeps to identify cycles, though \rustgc performs cycle detection
automatically (i.e.~it doesn't require manual calls to a function such as
\lstinline{collect_cycles}). Drop methods are not used as finalizers: if a
finalizer is required, a manual implementation of the \lstinline{Finalize} trait
must be provided; finalizer glue can be largely, though not fully (see
\cref{sec:destructor challenges}), automatically created by use of the provided
\lstinline{trace} macro . \laurie{does \rustgc solve the `finalizers mustn't do
things with cycles' problem?}

To move beyond reference counting as an aspect of GC for Rust, some
libraries have experimented with alternative mechanisms for finding roots.
\shifgrethor~\cite{shifgrethor} requires \lstinline{Gc} values to
be created by a \lstinline{Root<'root>} value; the former become references of
the latter, implicitly tying the lifetime of a \lstinline{Gc<'root, T>} to a
\lstinline{Root<'root>}. This allows roots to be precisely identified, but
requires explicitly having access to a \lstinline{Root<'root>} whenever a
\lstinline{Gc<'root, T>} is used. As with \rustgc, \shifgrethor requires users
to manually implement a \lstinline{Finalize} trait, though \shifgrethor's is
more restrictive: not only can other GCed values not be accessed (implicitly
solving the same problem as \cref{sec:cycles_and_finalization}) but any other
type type without the same \lstinline{'root} lifetime as the GCed value is
forbidden. In practise, this means that many finalizers require
implementing the unsafe \lstinline{UnsafeFinalize} trait. We view
\shifgrethor as proof that accurately tracking GC roots
in normal Rust is possible, though not yet easy.

A different means of tackling the root-finding problem is \textsc{GcArena}~\citep{gcarena}. In
essence, \textsc{GcArena} uses `branding' in a similar way to
\lstinline{GhostCell}s (see \cref{sec:background}), executing a function
within the context of an arena: when that function finishes, the arena can be
freed. Not only does this solve the problem of finding roots, but it is able to
implicitly free cycles. However, it is possible for code to keep executing in
an arena for too long, at which point the system can be starved of resources
even if much of the arena is no longer used. \textsc{GcArena} was originally
part of the \emph{Piccolo} VM  (which was itself previously called
\emph{Luster}), a Lua VM written in Rust. Such VMs have a main loop which is a
natural point for an arena-using function, but this is not true of many other
GC-using programs.

One of several extensions of \rustgc is \textsc{Bronze}, which aims to improve
upon \rustgc in two ways~\citep{coblenz21bronze}. First, \textsc{Bronze} tries
to solve the root-finding problem by using LLVM's \lstinline{gc.root} intrinsic
at function entries to generate stackmaps (a run-time mechanism for accurately
tracking active pointers). Unlike \ourgc, \textsc{Bronze} cannot accidentally
keep objects alive due to false positive `pointers'. However, \textsc{Bronze}
does not track nested references: if a \lstinline{Gc<T>} is used as a field in a struct, it will not
be tracked for GC purposes, leading to crashes. Second, \textsc{Bronze} tries to give GC in
Rust similar semantics to non-ownership languages such as Java. It does this by
allowing shared mutation, undermining Rust's borrow checker, and undermining
the soundness of seemingly safe Rust code (see \cref{lst:bronze_unsound} for an
example of a program which has undefined behaviour).


\subsection{Other relevant work}

\laurie{i'm not sure this tells us much? is there something else useful we can say about D?}
The D programming language uses a conservative mark-sweep GC for heap
allocations by default with support for opt-in explicit deallocation. Like \ourgc, D does
not specify an order for finalizers. Users can specify their own allocators for
RAII-based heap allocation using standard \lstinline{malloc}/\lstinline{free}
calls.

Chrome's rendering engine \emph{Blink} uses a conservative GC called
\textsc{Oilpan}. It has the interesting property that it has two classes of
finalizers. `Full finalizers' are similar to finalizers in \ourgc, running on a
finalizer thread at an indeterminate future point, but with the difference that
they can only reference parts of a GCed value. To mitigate this,
`pre-finalizers' are run as soon as an object as recognised as unused, and can
access all of a GCed value. Pre-finalizers are not encouraged, because they
hold up the GC. This reflects very different needs for \textsc{Oilpan} and
\ourgc: latency is a significant issue for \emph{Blink} but not something we
consider vital for \ourgc; instead we worry about the performance overhead of
finalization on a separate thread.


\section{Conclusions}

In this paper we have introduced a novel design for GC in Rust, and shown how
it solves some classical GC finalizer problems. We implemented our design in a
fork of \rustc, and showed that it has a fairly small performance overhead. We
do not claim that \ourgc is the best, final, design for GC in Rust, but it does
show how much can be achieved if one is willing to adjust and extend the
language design and, in particular, \rustc.

\bibliographystyle{ACM-Reference-Format}
\bibliography{bib}

\clearpage

\appendix

\section{Algorithms}

In this appendix, we show more formal versions of the algorithm descriptions
from the main body of the paper for those who may benefit from them.

\begin{figure}[b]
\begin{algorithmic}
\Function{RemoveElidableDrops}{$func$}
      \ForEach {$basic\_block \in func$}
            \If {\Call{IsDropTerminator}{$basic\_block.terminator.kind$}}
                \State $ty \gets$ \Call{GetTypeOfDroppedValue}{$block.terminator$}
                \If {\Call{IsGcType}{$ty$}}
                    \If {\NOT \Call{RequiresFinalizer}{$ty$}}
                        \State \Call{ReplaceTerminator}{$basic\_block$}
                    \EndIf
                \EndIf
            \EndIf
      \EndFor
\EndFunction
\Function{ReplaceTerminator}{$basic\_block$}
    \State $drop\_func \gets$ \Call{GetDropFunc}{$basic\_block.terminator$}
    \State $last\_block \gets$ \Call{GetLastBasicBlock}{$drop\_func$}
    \State $block.terminator \gets last\_block.terminator$
\EndFunction
\end{algorithmic}
% \end{algorithm}
  \captionof{algorithm}{The MIR pass for removing premature finalizer barriers
  for types with elided finalizers. This pass is registered inside \rustc,
  where it is invoked on all \textit{func}s in the program. The
  \textit{RemoveElidableDrops} iterates each basic block in a function in order
  to inspect whether the terminator is a call to a drop method as these are the
  only terminators of interest in this pass. If a ``drop terminator'' is found,
  then we check the type of the value being dropped. If the type of the value
  being dropped is a \lstinline{Gc<T>}, and its finalizer can be elided, then
  the drop terminator can be replaced. We can then replace these terminators by
  ``leaping over'' the drop method and patching it to the next basic block in
  the control flow.}
  \label{alg:barrier_removal}
\end{figure}

\clearpage

\section{Detailed Plots}

In this appendix, we show detailed plots for the experiments from the main body
of the paper for those who may benefit from them.

\begin{figure}[t!]
    \centering
    \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=1\textwidth]{plots/grmtools.pdf}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=1\textwidth]{plots/grmtools_mem.pdf}
    \end{subfigure}
    \caption{Performance (left) and memory (right) results of the \grmtools
    experiment. Each benchmark is run for 30 process executions, where the
    error bars represent 99\% confidence intervals.\jake{Parsing all java
    source files of 4 of the biggest open source java repos.}\jake{Number of
    .java source files processed: jenkins (1804), hadoop(12092), eclipse(5394),
    spring(8757)} \laurie{i'm surprised by the memory benchmarks: how can alloy be using so much less memory than Rc given that, by definition, alloy must be keeping memory alive for longer?}}
\label{fig:grmtools}
\end{figure}

\begin{figure}[t!]
    \centering
    \begin{subfigure}{\textwidth}
    \includegraphics[width=1\textwidth]{plots/som_rs_ast_elision.pdf}
    \caption{\somrsast}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
    \includegraphics[width=1\textwidth]{plots/som_rs_bc_elision.pdf}
    \caption{\somrsbc}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
    \includegraphics[width=1\textwidth]{plots/yksom_elision.pdf}
    \caption{\yksom}
    \end{subfigure}
    \caption{Results of a performance of \Eelision using two configurations: naive
    finalization (where no optimisation is performed); and \ourgc's finalizer
    elision optimisation (where finalizers which are used only to deallocate
    memory are removed). Each benchmark is run for \benchmarkpexecs process executions, where
    the error bars represent 99\% confidence intervals.}
\label{plot:elision_breakdown}
\end{figure}

\begin{figure}[t!]
    \centering
    \begin{subfigure}{\textwidth}
    \includegraphics[width=1\textwidth]{plots/som_rs_ast_barriers.pdf}
    \caption{\somrsast}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
    \includegraphics[width=1\textwidth]{plots/som_rs_bc_barriers.pdf}
    \caption{\somrsbc}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
    \includegraphics[width=1\textwidth]{plots/yksom_barriers.pdf}
    \caption{\yksom}
    \end{subfigure}
     \caption{Results showing the performance of \Epremopt on the SOM VMs, each
     of which use three configurations: \textit{None} where there are no
     compiler barriers (which is unsound); \textit{All}, where every single
     \lstinline{Gc} reference has a corresponding barrier; and \textit{None},
     where barriers are optimised away using \ourgc's optimisation (section
     \jake{XYZ}) Each benchmark is run for \benchmarkpexecs process executions, where
    the error bars represent 99\% confidence intervals.}
\label{plot:barriers_breakdown}
\end{figure}

\begin{figure}[!t]
\begin{lstrustsmall}
fn main() {
    let mut gr1 = GcRef::new(vec![1u16,2,3]);
    let mut gr2 = gr1.clone();

    let ref1 = gr1.as_mut();
    let ref2 = gr2.as_mut();

    // ref1 and ref2 now reference the same object:
    ref1.push(4);
    ref2.push(5);
    ref1.push(6);

    let ref1elem0 = ref1.get_mut(0).unwrap();
    // Force reallocation of the underlying vec
    ref2.resize(1024, 0);
    // Now this writes to deallocated memory
    *ref1elem0 = 42;
}
\end{lstrustsmall}
    \caption{An example of unsoundness in Bronze based on its ability to allow
    aliased mutable references. Here, we obtain two mutable references to the
    same underlying vector (lines 5-6), before using the second reference to
    resize the vector, which forces its backing store to be reallocated in
    memory (line 15). Later, when we try to access an element through the first
    reference, it no longer points to valid memory (line 15).
    } \label{lst:bronze_unsound}
\end{figure}

\end{document}
